{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os as os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import imageio\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly import tools\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout, BatchNormalization,LeakyReLU\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IMAGE_PATH = './Data/honey-bee-annotated-images/bee_imgs/bee_imgs/'\n",
    "IMAGE_WIDTH = 100\n",
    "IMAGE_HEIGHT = 100\n",
    "IMAGE_CHANNELS = 3\n",
    "RANDOM_STATE = 2018\n",
    "TEST_SIZE = 0.2\n",
    "VAL_SIZE = 0.2\n",
    "CONV_2D_DIM_1 = 16\n",
    "CONV_2D_DIM_2 = 16\n",
    "CONV_2D_DIM_3 = 32\n",
    "CONV_2D_DIM_4 = 64\n",
    "MAX_POOL_DIM = 2\n",
    "KERNEL_SIZE = 3\n",
    "BATCH_SIZE = 32\n",
    "NO_EPOCHS_1 = 5\n",
    "NO_EPOCHS_2 = 15\n",
    "NO_EPOCHS_3 = 50\n",
    "PATIENCE = 5\n",
    "VERBOSE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bee_data.csv', 'bee_dataset_clean.csv', 'bee_imgs']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"./Data/honey-bee-annotated-images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bee_data = pd.read_csv(\"./Data/honey-bee-annotated-images/bee_dataset_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5172, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bee_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>zip code</th>\n",
       "      <th>subspecies</th>\n",
       "      <th>health</th>\n",
       "      <th>pollen_carrying</th>\n",
       "      <th>caste</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "      <th>is_healthy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>032_572.png</td>\n",
       "      <td>8/21/18</td>\n",
       "      <td>9:00</td>\n",
       "      <td>50315</td>\n",
       "      <td>Russian honey bee</td>\n",
       "      <td>healthy</td>\n",
       "      <td>False</td>\n",
       "      <td>worker</td>\n",
       "      <td>Des Moines</td>\n",
       "      <td>IA</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5135</th>\n",
       "      <td>033_058.png</td>\n",
       "      <td>8/21/18</td>\n",
       "      <td>9:30</td>\n",
       "      <td>50315</td>\n",
       "      <td>Western honey bee</td>\n",
       "      <td>healthy</td>\n",
       "      <td>False</td>\n",
       "      <td>worker</td>\n",
       "      <td>Des Moines</td>\n",
       "      <td>IA</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>008_255.png</td>\n",
       "      <td>8/16/18</td>\n",
       "      <td>8:20</td>\n",
       "      <td>70115</td>\n",
       "      <td>VSH Italian honey bee</td>\n",
       "      <td>healthy</td>\n",
       "      <td>False</td>\n",
       "      <td>worker</td>\n",
       "      <td>New Orleans</td>\n",
       "      <td>LA</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4550</th>\n",
       "      <td>038_368.png</td>\n",
       "      <td>8/18/18</td>\n",
       "      <td>12:30</td>\n",
       "      <td>30607</td>\n",
       "      <td>1 Mixed local stock 2</td>\n",
       "      <td>Varroa, Small Hive Beetles</td>\n",
       "      <td>False</td>\n",
       "      <td>worker</td>\n",
       "      <td>Athens</td>\n",
       "      <td>GA</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2361</th>\n",
       "      <td>031_113.png</td>\n",
       "      <td>8/21/18</td>\n",
       "      <td>15:56</td>\n",
       "      <td>30607</td>\n",
       "      <td>Italian honey bee</td>\n",
       "      <td>few varrao, hive beetles</td>\n",
       "      <td>False</td>\n",
       "      <td>worker</td>\n",
       "      <td>Athens</td>\n",
       "      <td>GA</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             file     date   time  zip code             subspecies  \\\n",
       "3981  032_572.png  8/21/18   9:00     50315      Russian honey bee   \n",
       "5135  033_058.png  8/21/18   9:30     50315      Western honey bee   \n",
       "630   008_255.png  8/16/18   8:20     70115  VSH Italian honey bee   \n",
       "4550  038_368.png  8/18/18  12:30     30607  1 Mixed local stock 2   \n",
       "2361  031_113.png  8/21/18  15:56     30607      Italian honey bee   \n",
       "\n",
       "                          health  pollen_carrying   caste         City State  \\\n",
       "3981                     healthy            False  worker   Des Moines    IA   \n",
       "5135                     healthy            False  worker   Des Moines    IA   \n",
       "630                      healthy            False  worker  New Orleans    LA   \n",
       "4550  Varroa, Small Hive Beetles            False  worker       Athens    GA   \n",
       "2361    few varrao, hive beetles            False  worker       Athens    GA   \n",
       "\n",
       "     Country  is_healthy  \n",
       "3981     USA           1  \n",
       "5135     USA           1  \n",
       "630      USA           1  \n",
       "4550     USA           0  \n",
       "2361     USA           0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bee_data.sample(100).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of image files: 5173\n"
     ]
    }
   ],
   "source": [
    "image_files = list(os.listdir(IMAGE_PATH))\n",
    "print(\"Number of image files: {}\".format(len(image_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching image names: 5172\n"
     ]
    }
   ],
   "source": [
    "file_names = list(bee_data['file'])\n",
    "print(\"Matching image names: {}\".format(len(set(file_names).intersection(image_files))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_image_sizes(file_name):\n",
    "    image = skimage.io.imread(IMAGE_PATH + file_name)\n",
    "    return list(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = np.stack(bee_data['file'].apply(read_image_sizes))\n",
    "df = pd.DataFrame(m,columns=['w','h','c'])\n",
    "bee_data = pd.concat([bee_data,df],axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>zip code</th>\n",
       "      <th>subspecies</th>\n",
       "      <th>health</th>\n",
       "      <th>pollen_carrying</th>\n",
       "      <th>caste</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "      <th>is_healthy</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>041_066.png</td>\n",
       "      <td>8/28/18</td>\n",
       "      <td>16:07</td>\n",
       "      <td>77511</td>\n",
       "      <td>-1</td>\n",
       "      <td>hive being robbed</td>\n",
       "      <td>False</td>\n",
       "      <td>worker</td>\n",
       "      <td>Alvin</td>\n",
       "      <td>TX</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>164</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>041_072.png</td>\n",
       "      <td>8/28/18</td>\n",
       "      <td>16:07</td>\n",
       "      <td>77511</td>\n",
       "      <td>-1</td>\n",
       "      <td>hive being robbed</td>\n",
       "      <td>False</td>\n",
       "      <td>worker</td>\n",
       "      <td>Alvin</td>\n",
       "      <td>TX</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "      <td>201</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>041_073.png</td>\n",
       "      <td>8/28/18</td>\n",
       "      <td>16:07</td>\n",
       "      <td>77511</td>\n",
       "      <td>-1</td>\n",
       "      <td>hive being robbed</td>\n",
       "      <td>False</td>\n",
       "      <td>worker</td>\n",
       "      <td>Alvin</td>\n",
       "      <td>TX</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>167</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>041_067.png</td>\n",
       "      <td>8/28/18</td>\n",
       "      <td>16:07</td>\n",
       "      <td>77511</td>\n",
       "      <td>-1</td>\n",
       "      <td>hive being robbed</td>\n",
       "      <td>False</td>\n",
       "      <td>worker</td>\n",
       "      <td>Alvin</td>\n",
       "      <td>TX</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>97</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>041_059.png</td>\n",
       "      <td>8/28/18</td>\n",
       "      <td>16:07</td>\n",
       "      <td>77511</td>\n",
       "      <td>-1</td>\n",
       "      <td>hive being robbed</td>\n",
       "      <td>False</td>\n",
       "      <td>worker</td>\n",
       "      <td>Alvin</td>\n",
       "      <td>TX</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          file     date   time  zip code subspecies             health  \\\n",
       "0  041_066.png  8/28/18  16:07     77511         -1  hive being robbed   \n",
       "1  041_072.png  8/28/18  16:07     77511         -1  hive being robbed   \n",
       "2  041_073.png  8/28/18  16:07     77511         -1  hive being robbed   \n",
       "3  041_067.png  8/28/18  16:07     77511         -1  hive being robbed   \n",
       "4  041_059.png  8/28/18  16:07     77511         -1  hive being robbed   \n",
       "\n",
       "   pollen_carrying   caste   City State Country  is_healthy    w    h  c  \n",
       "0            False  worker  Alvin    TX     USA           0  115  164  3  \n",
       "1            False  worker  Alvin    TX     USA           0  201   90  3  \n",
       "2            False  worker  Alvin    TX     USA           0  132  167  3  \n",
       "3            False  worker  Alvin    TX     USA           0  134   97  3  \n",
       "4            False  worker  Alvin    TX     USA           0  147  106  3  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bee_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set rows: 3309\n",
      "Test  set rows: 1035\n",
      "Val   set rows: 828\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(bee_data, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "train_df, val_df = train_test_split(train_df, test_size=VAL_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "print(\"Train set rows: {}\".format(train_df.shape[0]))\n",
    "print(\"Test  set rows: {}\".format(test_df.shape[0]))\n",
    "print(\"Val   set rows: {}\".format(val_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#A function for reading images from the image files, scale all images to 100 x 100 x 3 (channels).\n",
    "\n",
    "def read_image(file_name):\n",
    "    image = skimage.io.imread(IMAGE_PATH + file_name)\n",
    "    image = skimage.transform.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT), mode='reflect')\n",
    "    return image[:,:,:IMAGE_CHANNELS]\n",
    "\n",
    "\n",
    "#A function to create the dummy variables corresponding to the categorical target variable.\n",
    "\n",
    "def categories_encoder(dataset, var='subspecies'):\n",
    "    X = np.stack(dataset['file'].apply(read_image))\n",
    "    y = pd.get_dummies(dataset[var], drop_first=False)\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = categories_encoder(train_df)\n",
    "X_val, y_val = categories_encoder(val_df)\n",
    "X_test, y_test = categories_encoder(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 100, 100, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 50, 50, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 50, 50, 16)        2320      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 40000)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 7)                 280007    \n",
      "=================================================================\n",
      "Total params: 282,775\n",
      "Trainable params: 282,775\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1=Sequential()\n",
    "model1.add(Conv2D(CONV_2D_DIM_1, kernel_size=KERNEL_SIZE, input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT,IMAGE_CHANNELS), activation='relu', padding='same'))\n",
    "model1.add(MaxPool2D(MAX_POOL_DIM))\n",
    "model1.add(Conv2D(CONV_2D_DIM_2, kernel_size=KERNEL_SIZE, activation='relu', padding='same'))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(y_train.columns.size, activation='softmax'))\n",
    "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_generator = ImageDataGenerator(\n",
    "                  featurewise_center=False,\n",
    "                  samplewise_center=False,\n",
    "                  featurewise_std_normalization=False,\n",
    "                  samplewise_std_normalization=False,\n",
    "                  zca_whitening=False,\n",
    "                  rotation_range=180,\n",
    "                  zoom_range = 0.1, \n",
    "                  width_shift_range=0.1,\n",
    "                  height_shift_range=0.1, \n",
    "                  horizontal_flip=True,\n",
    "                  vertical_flip=True)\n",
    "image_generator.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-d5aaefbf77b8>:4: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/5\n",
      "104/103 [==============================] - 12s 111ms/step - loss: 1.0589 - accuracy: 0.6485 - val_loss: 0.7271 - val_accuracy: 0.7488\n",
      "Epoch 2/5\n",
      "104/103 [==============================] - 11s 105ms/step - loss: 0.5512 - accuracy: 0.7839 - val_loss: 0.5492 - val_accuracy: 0.8019\n",
      "Epoch 3/5\n",
      "104/103 [==============================] - 11s 106ms/step - loss: 0.4471 - accuracy: 0.8341 - val_loss: 0.4632 - val_accuracy: 0.8454\n",
      "Epoch 4/5\n",
      "104/103 [==============================] - 11s 106ms/step - loss: 0.4144 - accuracy: 0.8392 - val_loss: 0.4134 - val_accuracy: 0.8587\n",
      "Epoch 5/5\n",
      "104/103 [==============================] - 11s 105ms/step - loss: 0.3903 - accuracy: 0.8435 - val_loss: 0.3545 - val_accuracy: 0.8647\n"
     ]
    }
   ],
   "source": [
    "train_model1 = model1.fit_generator(image_generator.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                        epochs=NO_EPOCHS_1,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        steps_per_epoch=len(X_train)/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3229786455631256\n",
      "Test accuracy: 0.8763285279273987\n"
     ]
    }
   ],
   "source": [
    "score = model1.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                   -1       0.87      0.84      0.85        80\n",
      "1 Mixed local stock 2       0.60      0.27      0.37        96\n",
      "  Carniolan honey bee       0.97      0.99      0.98       102\n",
      "    Italian honey bee       0.86      0.96      0.91       601\n",
      "    Russian honey bee       0.94      0.98      0.96        98\n",
      "VSH Italian honey bee       1.00      0.63      0.78        49\n",
      "    Western honey bee       1.00      0.78      0.88         9\n",
      "\n",
      "             accuracy                           0.88      1035\n",
      "            macro avg       0.89      0.78      0.82      1035\n",
      "         weighted avg       0.87      0.88      0.86      1035\n",
      "\n",
      "Loss function: 0.3229786455631256, accuracy: 0.8763285279273987\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def test_accuracy_report(model):\n",
    "    predicted = model.predict(X_test)\n",
    "    test_predicted = np.argmax(predicted, axis=1)\n",
    "    test_truth = np.argmax(y_test.values, axis=1)\n",
    "    print(metrics.classification_report(test_truth, test_predicted, target_names=y_test.columns)) \n",
    "    test_res = model.evaluate(X_test, y_test.values, verbose=0)\n",
    "    print('Loss function: %s, accuracy:' % test_res[0], test_res[1])\n",
    "test_accuracy_report(model1)\n",
    "print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model2 with Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 100, 100, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 50, 50, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50, 50, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 50, 50, 16)        2320      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 50, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 40000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 280007    \n",
      "=================================================================\n",
      "Total params: 282,775\n",
      "Trainable params: 282,775\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2=Sequential()\n",
    "model2.add(Conv2D(CONV_2D_DIM_1, kernel_size=KERNEL_SIZE, input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT,IMAGE_CHANNELS), activation='relu', padding='same'))\n",
    "model2.add(MaxPool2D(MAX_POOL_DIM))\n",
    "model2.add(Dropout(0.4))\n",
    "model2.add(Conv2D(CONV_2D_DIM_2, kernel_size=KERNEL_SIZE, activation='relu', padding='same'))\n",
    "model2.add(Dropout(0.4))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(y_train.columns.size, activation='softmax'))\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "104/103 [==============================] - 14s 132ms/step - loss: 1.1020 - accuracy: 0.6464 - val_loss: 1.0084 - val_accuracy: 0.6002\n",
      "Epoch 2/15\n",
      "104/103 [==============================] - 16s 154ms/step - loss: 0.6565 - accuracy: 0.7643 - val_loss: 0.5896 - val_accuracy: 0.7874\n",
      "Epoch 3/15\n",
      "104/103 [==============================] - 13s 123ms/step - loss: 0.5105 - accuracy: 0.8030 - val_loss: 0.5041 - val_accuracy: 0.8213\n",
      "Epoch 4/15\n",
      "104/103 [==============================] - 13s 122ms/step - loss: 0.4499 - accuracy: 0.8277 - val_loss: 0.5660 - val_accuracy: 0.7971\n",
      "Epoch 5/15\n",
      "104/103 [==============================] - 12s 119ms/step - loss: 0.4089 - accuracy: 0.8365 - val_loss: 0.5143 - val_accuracy: 0.8080\n",
      "Epoch 6/15\n",
      "104/103 [==============================] - 13s 121ms/step - loss: 0.3538 - accuracy: 0.8549 - val_loss: 0.3507 - val_accuracy: 0.8684\n",
      "Epoch 7/15\n",
      "104/103 [==============================] - 12s 118ms/step - loss: 0.3597 - accuracy: 0.8540 - val_loss: 0.4001 - val_accuracy: 0.8430\n",
      "Epoch 8/15\n",
      "104/103 [==============================] - 12s 118ms/step - loss: 0.3359 - accuracy: 0.8595 - val_loss: 0.3468 - val_accuracy: 0.8599\n",
      "Epoch 9/15\n",
      "104/103 [==============================] - 12s 115ms/step - loss: 0.3255 - accuracy: 0.8673 - val_loss: 0.3421 - val_accuracy: 0.8623\n",
      "Epoch 10/15\n",
      "104/103 [==============================] - 12s 117ms/step - loss: 0.2964 - accuracy: 0.8722 - val_loss: 0.2949 - val_accuracy: 0.8804\n",
      "Epoch 11/15\n",
      "104/103 [==============================] - 12s 117ms/step - loss: 0.2843 - accuracy: 0.8697 - val_loss: 0.3927 - val_accuracy: 0.8430\n",
      "Epoch 12/15\n",
      "104/103 [==============================] - 12s 116ms/step - loss: 0.2851 - accuracy: 0.8770 - val_loss: 0.3161 - val_accuracy: 0.8732\n",
      "Epoch 13/15\n",
      "104/103 [==============================] - 12s 117ms/step - loss: 0.2842 - accuracy: 0.8743 - val_loss: 0.3169 - val_accuracy: 0.8647\n",
      "Epoch 14/15\n",
      "104/103 [==============================] - 12s 118ms/step - loss: 0.2749 - accuracy: 0.8767 - val_loss: 0.3799 - val_accuracy: 0.8382\n",
      "Epoch 15/15\n",
      "104/103 [==============================] - 12s 118ms/step - loss: 0.2724 - accuracy: 0.8861 - val_loss: 0.2836 - val_accuracy: 0.8865\n"
     ]
    }
   ],
   "source": [
    "train_model2  = model2.fit_generator(image_generator.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                        epochs=NO_EPOCHS_2,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        steps_per_epoch=len(X_train)/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                   -1       0.94      0.78      0.85        80\n",
      "1 Mixed local stock 2       0.58      0.83      0.68        96\n",
      "  Carniolan honey bee       0.92      1.00      0.96       102\n",
      "    Italian honey bee       0.96      0.89      0.92       601\n",
      "    Russian honey bee       0.92      1.00      0.96        98\n",
      "VSH Italian honey bee       0.88      0.86      0.87        49\n",
      "    Western honey bee       1.00      0.78      0.88         9\n",
      "\n",
      "             accuracy                           0.90      1035\n",
      "            macro avg       0.89      0.88      0.87      1035\n",
      "         weighted avg       0.91      0.90      0.90      1035\n",
      "\n",
      "Loss function: 0.265487939119339, accuracy: 0.895652174949646\n"
     ]
    }
   ],
   "source": [
    "test_accuracy_report(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_trace(x,y,ylabel,color):\n",
    "        trace = go.Scatter(\n",
    "            x = x,y = y,\n",
    "            name=ylabel,\n",
    "            marker=dict(color=color),\n",
    "            mode = \"markers+lines\",\n",
    "            text=x\n",
    "        )\n",
    "        return trace\n",
    "    \n",
    "def plot_accuracy_and_loss(train_model):\n",
    "    hist = train_model.history\n",
    "    acc = hist['accuracy']\n",
    "    val_acc = hist['val_accuracy']\n",
    "    loss = hist['loss']\n",
    "    val_loss = hist['val_loss']\n",
    "    epochs = list(range(1,len(acc)+1))\n",
    "    #define the traces\n",
    "    trace_ta = create_trace(epochs,acc,\"Training accuracy\", \"Green\")\n",
    "    trace_va = create_trace(epochs,val_acc,\"Validation accuracy\", \"Red\")\n",
    "    trace_tl = create_trace(epochs,loss,\"Training loss\", \"Blue\")\n",
    "    trace_vl = create_trace(epochs,val_loss,\"Validation loss\", \"Magenta\")\n",
    "    fig = tools.make_subplots(rows=1,cols=2, subplot_titles=('Training and validation accuracy',\n",
    "                                                             'Training and validation loss'))\n",
    "    #add traces to the figure\n",
    "    fig.append_trace(trace_ta,1,1)\n",
    "    fig.append_trace(trace_va,1,1)\n",
    "    fig.append_trace(trace_tl,1,2)\n",
    "    fig.append_trace(trace_vl,1,2)\n",
    "    #set the layout for the figure\n",
    "    fig['layout']['xaxis'].update(title = 'Epoch')\n",
    "    fig['layout']['xaxis2'].update(title = 'Epoch')\n",
    "    fig['layout']['yaxis'].update(title = 'Accuracy', range=[0,1])\n",
    "    fig['layout']['yaxis2'].update(title = 'Loss', range=[0,1])\n",
    "    #plot\n",
    "    iplot(fig, filename='accuracy-loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "marker": {
          "color": "Green"
         },
         "mode": "markers+lines",
         "name": "Training accuracy",
         "text": [
          "1",
          "2",
          "3",
          "4",
          "5"
         ],
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5
         ],
         "xaxis": "x",
         "y": [
          0.6485342979431152,
          0.7839226126670837,
          0.8340888619422913,
          0.8392263650894165,
          0.8434572219848633
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "Red"
         },
         "mode": "markers+lines",
         "name": "Validation accuracy",
         "text": [
          "1",
          "2",
          "3",
          "4",
          "5"
         ],
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5
         ],
         "xaxis": "x",
         "y": [
          0.748792290687561,
          0.8019323945045471,
          0.8454106450080872,
          0.8586956262588501,
          0.8647342920303345
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "Blue"
         },
         "mode": "markers+lines",
         "name": "Training loss",
         "text": [
          "1",
          "2",
          "3",
          "4",
          "5"
         ],
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5
         ],
         "xaxis": "x2",
         "y": [
          1.058856725692749,
          0.5511878728866577,
          0.4471217095851898,
          0.41441336274147034,
          0.3903074860572815
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "Magenta"
         },
         "mode": "markers+lines",
         "name": "Validation loss",
         "text": [
          "1",
          "2",
          "3",
          "4",
          "5"
         ],
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5
         ],
         "xaxis": "x2",
         "y": [
          0.7271333336830139,
          0.5492282509803772,
          0.4632337987422943,
          0.41336655616760254,
          0.3544633984565735
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Training and validation accuracy",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Training and validation loss",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "range": [
          0,
          1
         ],
         "title": {
          "text": "Accuracy"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ],
         "range": [
          0,
          1
         ],
         "title": {
          "text": "Loss"
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"49d2cba0-8d30-4a5d-b418-f013d011201f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"49d2cba0-8d30-4a5d-b418-f013d011201f\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '49d2cba0-8d30-4a5d-b418-f013d011201f',\n",
       "                        [{\"marker\": {\"color\": \"Green\"}, \"mode\": \"markers+lines\", \"name\": \"Training accuracy\", \"text\": [\"1\", \"2\", \"3\", \"4\", \"5\"], \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5], \"xaxis\": \"x\", \"y\": [0.6485342979431152, 0.7839226126670837, 0.8340888619422913, 0.8392263650894165, 0.8434572219848633], \"yaxis\": \"y\"}, {\"marker\": {\"color\": \"Red\"}, \"mode\": \"markers+lines\", \"name\": \"Validation accuracy\", \"text\": [\"1\", \"2\", \"3\", \"4\", \"5\"], \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5], \"xaxis\": \"x\", \"y\": [0.748792290687561, 0.8019323945045471, 0.8454106450080872, 0.8586956262588501, 0.8647342920303345], \"yaxis\": \"y\"}, {\"marker\": {\"color\": \"Blue\"}, \"mode\": \"markers+lines\", \"name\": \"Training loss\", \"text\": [\"1\", \"2\", \"3\", \"4\", \"5\"], \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5], \"xaxis\": \"x2\", \"y\": [1.058856725692749, 0.5511878728866577, 0.4471217095851898, 0.41441336274147034, 0.3903074860572815], \"yaxis\": \"y2\"}, {\"marker\": {\"color\": \"Magenta\"}, \"mode\": \"markers+lines\", \"name\": \"Validation loss\", \"text\": [\"1\", \"2\", \"3\", \"4\", \"5\"], \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5], \"xaxis\": \"x2\", \"y\": [0.7271333336830139, 0.5492282509803772, 0.4632337987422943, 0.41336655616760254, 0.3544633984565735], \"yaxis\": \"y2\"}],\n",
       "                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Training and validation accuracy\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Training and validation loss\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45], \"title\": {\"text\": \"Epoch\"}}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0], \"title\": {\"text\": \"Epoch\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"range\": [0, 1], \"title\": {\"text\": \"Accuracy\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0], \"range\": [0, 1], \"title\": {\"text\": \"Loss\"}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('49d2cba0-8d30-4a5d-b418-f013d011201f');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_accuracy_and_loss(train_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3229786455631256\n",
      "Test accuracy: 0.8763285279273987\n"
     ]
    }
   ],
   "source": [
    "score = model1.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "marker": {
          "color": "Green"
         },
         "mode": "markers+lines",
         "name": "Training accuracy",
         "text": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12",
          "13",
          "14",
          "15"
         ],
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15
         ],
         "xaxis": "x",
         "y": [
          0.6464188694953918,
          0.7642792463302612,
          0.8029616475105286,
          0.8277425169944763,
          0.8365064859390259,
          0.8549410700798035,
          0.854034423828125,
          0.8594741821289062,
          0.8673315048217773,
          0.8721668124198914,
          0.8697491884231567,
          0.8770021200180054,
          0.8742822408676147,
          0.8766999244689941,
          0.8860682845115662
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "Red"
         },
         "mode": "markers+lines",
         "name": "Validation accuracy",
         "text": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12",
          "13",
          "14",
          "15"
         ],
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15
         ],
         "xaxis": "x",
         "y": [
          0.6002415418624878,
          0.7874395847320557,
          0.8212560415267944,
          0.7971014380455017,
          0.8079710006713867,
          0.8683574795722961,
          0.8429951667785645,
          0.8599033951759338,
          0.8623188138008118,
          0.8804348111152649,
          0.8429951667785645,
          0.8731883764266968,
          0.8647342920303345,
          0.8381642699241638,
          0.8864734172821045
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "Blue"
         },
         "mode": "markers+lines",
         "name": "Training loss",
         "text": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12",
          "13",
          "14",
          "15"
         ],
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15
         ],
         "xaxis": "x2",
         "y": [
          1.1020325422286987,
          0.6565282940864563,
          0.5105336308479309,
          0.4498712718486786,
          0.40888696908950806,
          0.35377445816993713,
          0.3597066402435303,
          0.3358909785747528,
          0.32550734281539917,
          0.2963573634624481,
          0.28430548310279846,
          0.285058856010437,
          0.28416940569877625,
          0.2748764455318451,
          0.27242258191108704
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "Magenta"
         },
         "mode": "markers+lines",
         "name": "Validation loss",
         "text": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12",
          "13",
          "14",
          "15"
         ],
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15
         ],
         "xaxis": "x2",
         "y": [
          1.0084267854690552,
          0.589645266532898,
          0.5040517449378967,
          0.5660348534584045,
          0.5143163800239563,
          0.35071054100990295,
          0.40007832646369934,
          0.3467633128166199,
          0.3421112298965454,
          0.2949148714542389,
          0.3927050828933716,
          0.3161439299583435,
          0.31693997979164124,
          0.37993088364601135,
          0.28357651829719543
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Training and validation accuracy",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Training and validation loss",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "range": [
          0,
          1
         ],
         "title": {
          "text": "Accuracy"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ],
         "range": [
          0,
          1
         ],
         "title": {
          "text": "Loss"
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"0dcb54e6-8ed1-41a1-aede-8b0fb6f8a188\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"0dcb54e6-8ed1-41a1-aede-8b0fb6f8a188\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '0dcb54e6-8ed1-41a1-aede-8b0fb6f8a188',\n",
       "                        [{\"marker\": {\"color\": \"Green\"}, \"mode\": \"markers+lines\", \"name\": \"Training accuracy\", \"text\": [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\"], \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], \"xaxis\": \"x\", \"y\": [0.6464188694953918, 0.7642792463302612, 0.8029616475105286, 0.8277425169944763, 0.8365064859390259, 0.8549410700798035, 0.854034423828125, 0.8594741821289062, 0.8673315048217773, 0.8721668124198914, 0.8697491884231567, 0.8770021200180054, 0.8742822408676147, 0.8766999244689941, 0.8860682845115662], \"yaxis\": \"y\"}, {\"marker\": {\"color\": \"Red\"}, \"mode\": \"markers+lines\", \"name\": \"Validation accuracy\", \"text\": [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\"], \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], \"xaxis\": \"x\", \"y\": [0.6002415418624878, 0.7874395847320557, 0.8212560415267944, 0.7971014380455017, 0.8079710006713867, 0.8683574795722961, 0.8429951667785645, 0.8599033951759338, 0.8623188138008118, 0.8804348111152649, 0.8429951667785645, 0.8731883764266968, 0.8647342920303345, 0.8381642699241638, 0.8864734172821045], \"yaxis\": \"y\"}, {\"marker\": {\"color\": \"Blue\"}, \"mode\": \"markers+lines\", \"name\": \"Training loss\", \"text\": [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\"], \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], \"xaxis\": \"x2\", \"y\": [1.1020325422286987, 0.6565282940864563, 0.5105336308479309, 0.4498712718486786, 0.40888696908950806, 0.35377445816993713, 0.3597066402435303, 0.3358909785747528, 0.32550734281539917, 0.2963573634624481, 0.28430548310279846, 0.285058856010437, 0.28416940569877625, 0.2748764455318451, 0.27242258191108704], \"yaxis\": \"y2\"}, {\"marker\": {\"color\": \"Magenta\"}, \"mode\": \"markers+lines\", \"name\": \"Validation loss\", \"text\": [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\"], \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], \"xaxis\": \"x2\", \"y\": [1.0084267854690552, 0.589645266532898, 0.5040517449378967, 0.5660348534584045, 0.5143163800239563, 0.35071054100990295, 0.40007832646369934, 0.3467633128166199, 0.3421112298965454, 0.2949148714542389, 0.3927050828933716, 0.3161439299583435, 0.31693997979164124, 0.37993088364601135, 0.28357651829719543], \"yaxis\": \"y2\"}],\n",
       "                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Training and validation accuracy\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Training and validation loss\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45], \"title\": {\"text\": \"Epoch\"}}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0], \"title\": {\"text\": \"Epoch\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"range\": [0, 1], \"title\": {\"text\": \"Accuracy\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0], \"range\": [0, 1], \"title\": {\"text\": \"Loss\"}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('0dcb54e6-8ed1-41a1-aede-8b0fb6f8a188');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_accuracy_and_loss(train_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.265487939119339\n",
      "Test accuracy: 0.895652174949646\n"
     ]
    }
   ],
   "source": [
    "score = model2.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.2731 - accuracy: 0.8843 - val_loss: 0.2755 - val_accuracy: 0.8853\n",
      "Epoch 2/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.2517 - accuracy: 0.8933 - val_loss: 0.2705 - val_accuracy: 0.8780\n",
      "Epoch 3/250\n",
      "104/103 [==============================] - 12s 114ms/step - loss: 0.2806 - accuracy: 0.8767 - val_loss: 0.2681 - val_accuracy: 0.8961\n",
      "Epoch 4/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.2376 - accuracy: 0.8945 - val_loss: 0.2904 - val_accuracy: 0.8792\n",
      "Epoch 5/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.2511 - accuracy: 0.8852 - val_loss: 0.3573 - val_accuracy: 0.8599\n",
      "Epoch 6/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.2713 - accuracy: 0.8812 - val_loss: 0.3675 - val_accuracy: 0.8370\n",
      "Epoch 7/250\n",
      "104/103 [==============================] - 12s 114ms/step - loss: 0.2375 - accuracy: 0.8954 - val_loss: 0.2571 - val_accuracy: 0.8925\n",
      "Epoch 8/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.2419 - accuracy: 0.8954 - val_loss: 0.2185 - val_accuracy: 0.9094\n",
      "Epoch 9/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.2363 - accuracy: 0.9006 - val_loss: 0.2927 - val_accuracy: 0.8756\n",
      "Epoch 10/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.2586 - accuracy: 0.8864 - val_loss: 0.2977 - val_accuracy: 0.8889\n",
      "Epoch 11/250\n",
      "104/103 [==============================] - 12s 114ms/step - loss: 0.2695 - accuracy: 0.8824 - val_loss: 0.2554 - val_accuracy: 0.9034\n",
      "Epoch 12/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.2340 - accuracy: 0.8921 - val_loss: 0.2511 - val_accuracy: 0.9034\n",
      "Epoch 13/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.2110 - accuracy: 0.9099 - val_loss: 0.2915 - val_accuracy: 0.8756\n",
      "Epoch 14/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.2146 - accuracy: 0.9000 - val_loss: 0.3007 - val_accuracy: 0.8696\n",
      "Epoch 15/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.2234 - accuracy: 0.9009 - val_loss: 0.2323 - val_accuracy: 0.8998\n",
      "Epoch 16/250\n",
      "104/103 [==============================] - 12s 114ms/step - loss: 0.2678 - accuracy: 0.8882 - val_loss: 0.3457 - val_accuracy: 0.8551\n",
      "Epoch 17/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.2222 - accuracy: 0.9030 - val_loss: 0.3229 - val_accuracy: 0.8720\n",
      "Epoch 18/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.2088 - accuracy: 0.9072 - val_loss: 0.2905 - val_accuracy: 0.8889\n",
      "Epoch 19/250\n",
      "104/103 [==============================] - 12s 115ms/step - loss: 0.2159 - accuracy: 0.8991 - val_loss: 0.2946 - val_accuracy: 0.8756\n",
      "Epoch 20/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.2166 - accuracy: 0.9066 - val_loss: 0.2588 - val_accuracy: 0.8949\n",
      "Epoch 21/250\n",
      "104/103 [==============================] - 12s 114ms/step - loss: 0.2110 - accuracy: 0.9069 - val_loss: 0.3212 - val_accuracy: 0.8816\n",
      "Epoch 22/250\n",
      "104/103 [==============================] - 12s 115ms/step - loss: 0.2328 - accuracy: 0.9009 - val_loss: 0.2592 - val_accuracy: 0.8841\n",
      "Epoch 23/250\n",
      "104/103 [==============================] - 12s 114ms/step - loss: 0.2319 - accuracy: 0.9024 - val_loss: 0.3382 - val_accuracy: 0.8575\n",
      "Epoch 24/250\n",
      "104/103 [==============================] - 12s 116ms/step - loss: 0.2172 - accuracy: 0.9075 - val_loss: 0.4142 - val_accuracy: 0.8490\n",
      "Epoch 25/250\n",
      "104/103 [==============================] - 12s 116ms/step - loss: 0.2110 - accuracy: 0.9045 - val_loss: 0.3308 - val_accuracy: 0.8671\n",
      "Epoch 26/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.2388 - accuracy: 0.8982 - val_loss: 0.2818 - val_accuracy: 0.8768\n",
      "Epoch 27/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.2047 - accuracy: 0.9096 - val_loss: 0.2531 - val_accuracy: 0.8986\n",
      "Epoch 28/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1999 - accuracy: 0.9133 - val_loss: 0.4765 - val_accuracy: 0.8285\n",
      "Epoch 29/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.2157 - accuracy: 0.9118 - val_loss: 0.2604 - val_accuracy: 0.8949\n",
      "Epoch 30/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.2019 - accuracy: 0.9139 - val_loss: 0.2814 - val_accuracy: 0.8961\n",
      "Epoch 31/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.2094 - accuracy: 0.9054 - val_loss: 0.2614 - val_accuracy: 0.8877\n",
      "Epoch 32/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1966 - accuracy: 0.9151 - val_loss: 0.2944 - val_accuracy: 0.8780\n",
      "Epoch 33/250\n",
      "104/103 [==============================] - 12s 112ms/step - loss: 0.2003 - accuracy: 0.9102 - val_loss: 0.3158 - val_accuracy: 0.8768\n",
      "Epoch 34/250\n",
      "104/103 [==============================] - 12s 114ms/step - loss: 0.1982 - accuracy: 0.9105 - val_loss: 0.2331 - val_accuracy: 0.9046\n",
      "Epoch 35/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1953 - accuracy: 0.9108 - val_loss: 0.2384 - val_accuracy: 0.9010\n",
      "Epoch 36/250\n",
      "104/103 [==============================] - 12s 114ms/step - loss: 0.1979 - accuracy: 0.9148 - val_loss: 0.2637 - val_accuracy: 0.8865\n",
      "Epoch 37/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.2357 - accuracy: 0.8969 - val_loss: 0.2438 - val_accuracy: 0.8986\n",
      "Epoch 38/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1785 - accuracy: 0.9190 - val_loss: 0.2430 - val_accuracy: 0.9022\n",
      "Epoch 39/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.2162 - accuracy: 0.9069 - val_loss: 0.2945 - val_accuracy: 0.8889\n",
      "Epoch 40/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.2083 - accuracy: 0.9024 - val_loss: 0.2309 - val_accuracy: 0.9082\n",
      "Epoch 41/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1810 - accuracy: 0.9226 - val_loss: 0.2206 - val_accuracy: 0.9143\n",
      "Epoch 42/250\n",
      "104/103 [==============================] - 12s 112ms/step - loss: 0.2005 - accuracy: 0.9157 - val_loss: 0.2569 - val_accuracy: 0.9022\n",
      "Epoch 43/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1787 - accuracy: 0.9214 - val_loss: 0.2735 - val_accuracy: 0.8913\n",
      "Epoch 44/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1806 - accuracy: 0.9226 - val_loss: 0.2399 - val_accuracy: 0.9106\n",
      "Epoch 45/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1958 - accuracy: 0.9130 - val_loss: 0.2786 - val_accuracy: 0.8913\n",
      "Epoch 46/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1696 - accuracy: 0.9248 - val_loss: 0.2479 - val_accuracy: 0.9022\n",
      "Epoch 47/250\n",
      "104/103 [==============================] - 12s 114ms/step - loss: 0.1901 - accuracy: 0.9127 - val_loss: 0.2196 - val_accuracy: 0.9155\n",
      "Epoch 48/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1911 - accuracy: 0.9220 - val_loss: 0.2787 - val_accuracy: 0.8901\n",
      "Epoch 49/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1744 - accuracy: 0.9229 - val_loss: 0.2319 - val_accuracy: 0.9058\n",
      "Epoch 50/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1836 - accuracy: 0.9211 - val_loss: 0.2948 - val_accuracy: 0.8841\n",
      "Epoch 51/250\n",
      "104/103 [==============================] - 12s 114ms/step - loss: 0.1828 - accuracy: 0.9199 - val_loss: 0.3025 - val_accuracy: 0.8901\n",
      "Epoch 52/250\n",
      "104/103 [==============================] - 12s 111ms/step - loss: 0.2242 - accuracy: 0.9093 - val_loss: 0.2833 - val_accuracy: 0.8853\n",
      "Epoch 53/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1879 - accuracy: 0.9184 - val_loss: 0.2490 - val_accuracy: 0.9046\n",
      "Epoch 54/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1793 - accuracy: 0.9214 - val_loss: 0.2843 - val_accuracy: 0.8804\n",
      "Epoch 55/250\n",
      "104/103 [==============================] - 12s 111ms/step - loss: 0.1855 - accuracy: 0.9205 - val_loss: 0.2452 - val_accuracy: 0.9058\n",
      "Epoch 56/250\n",
      "104/103 [==============================] - 12s 111ms/step - loss: 0.1937 - accuracy: 0.9169 - val_loss: 0.2310 - val_accuracy: 0.9070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/250\n",
      "104/103 [==============================] - 11s 109ms/step - loss: 0.1963 - accuracy: 0.9154 - val_loss: 0.2979 - val_accuracy: 0.8720\n",
      "Epoch 58/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1851 - accuracy: 0.9248 - val_loss: 0.2391 - val_accuracy: 0.9022\n",
      "Epoch 59/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1765 - accuracy: 0.9269 - val_loss: 0.2362 - val_accuracy: 0.9167\n",
      "Epoch 60/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1667 - accuracy: 0.9269 - val_loss: 0.2127 - val_accuracy: 0.9106\n",
      "Epoch 61/250\n",
      "104/103 [==============================] - 11s 109ms/step - loss: 0.1650 - accuracy: 0.9311 - val_loss: 0.2711 - val_accuracy: 0.8925\n",
      "Epoch 62/250\n",
      "104/103 [==============================] - 12s 111ms/step - loss: 0.1835 - accuracy: 0.9190 - val_loss: 0.2111 - val_accuracy: 0.9203\n",
      "Epoch 63/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1751 - accuracy: 0.9275 - val_loss: 0.2987 - val_accuracy: 0.8768\n",
      "Epoch 64/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1805 - accuracy: 0.9196 - val_loss: 0.2328 - val_accuracy: 0.9179\n",
      "Epoch 65/250\n",
      "104/103 [==============================] - 11s 109ms/step - loss: 0.1723 - accuracy: 0.9248 - val_loss: 0.2486 - val_accuracy: 0.9070\n",
      "Epoch 66/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1924 - accuracy: 0.9196 - val_loss: 0.2283 - val_accuracy: 0.9106\n",
      "Epoch 67/250\n",
      "104/103 [==============================] - 11s 109ms/step - loss: 0.2097 - accuracy: 0.9133 - val_loss: 0.2569 - val_accuracy: 0.8986\n",
      "Epoch 68/250\n",
      "104/103 [==============================] - 11s 111ms/step - loss: 0.1699 - accuracy: 0.9302 - val_loss: 0.2587 - val_accuracy: 0.8937\n",
      "Epoch 69/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1693 - accuracy: 0.9220 - val_loss: 0.2416 - val_accuracy: 0.9130\n",
      "Epoch 70/250\n",
      "104/103 [==============================] - 12s 111ms/step - loss: 0.1739 - accuracy: 0.9205 - val_loss: 0.1979 - val_accuracy: 0.9155\n",
      "Epoch 71/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1553 - accuracy: 0.9296 - val_loss: 0.2496 - val_accuracy: 0.9094\n",
      "Epoch 72/250\n",
      "104/103 [==============================] - 11s 109ms/step - loss: 0.1742 - accuracy: 0.9260 - val_loss: 0.2700 - val_accuracy: 0.9022\n",
      "Epoch 73/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1718 - accuracy: 0.9235 - val_loss: 0.3144 - val_accuracy: 0.8841\n",
      "Epoch 74/250\n",
      "104/103 [==============================] - 11s 109ms/step - loss: 0.1828 - accuracy: 0.9187 - val_loss: 0.2202 - val_accuracy: 0.9143\n",
      "Epoch 75/250\n",
      "104/103 [==============================] - 12s 114ms/step - loss: 0.1661 - accuracy: 0.9293 - val_loss: 0.2033 - val_accuracy: 0.9239\n",
      "Epoch 76/250\n",
      "104/103 [==============================] - 12s 119ms/step - loss: 0.1583 - accuracy: 0.9244 - val_loss: 0.2342 - val_accuracy: 0.9118\n",
      "Epoch 77/250\n",
      "104/103 [==============================] - 13s 120ms/step - loss: 0.1764 - accuracy: 0.9178 - val_loss: 0.2456 - val_accuracy: 0.9034\n",
      "Epoch 78/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1724 - accuracy: 0.9308 - val_loss: 0.2413 - val_accuracy: 0.9070\n",
      "Epoch 79/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1693 - accuracy: 0.9287 - val_loss: 0.2288 - val_accuracy: 0.9203\n",
      "Epoch 80/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1754 - accuracy: 0.9232 - val_loss: 0.2323 - val_accuracy: 0.9179\n",
      "Epoch 81/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1678 - accuracy: 0.9223 - val_loss: 0.2397 - val_accuracy: 0.8986\n",
      "Epoch 82/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1728 - accuracy: 0.9269 - val_loss: 0.2419 - val_accuracy: 0.9010\n",
      "Epoch 83/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1652 - accuracy: 0.9263 - val_loss: 0.2203 - val_accuracy: 0.9143\n",
      "Epoch 84/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1521 - accuracy: 0.9326 - val_loss: 0.1818 - val_accuracy: 0.9396\n",
      "Epoch 85/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1825 - accuracy: 0.9257 - val_loss: 0.2362 - val_accuracy: 0.9191\n",
      "Epoch 86/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1906 - accuracy: 0.9199 - val_loss: 0.2167 - val_accuracy: 0.9215\n",
      "Epoch 87/250\n",
      "104/103 [==============================] - 12s 114ms/step - loss: 0.1688 - accuracy: 0.9241 - val_loss: 0.2405 - val_accuracy: 0.9058\n",
      "Epoch 88/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1519 - accuracy: 0.9263 - val_loss: 0.2325 - val_accuracy: 0.9155\n",
      "Epoch 89/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1741 - accuracy: 0.9244 - val_loss: 0.2044 - val_accuracy: 0.9251\n",
      "Epoch 90/250\n",
      "104/103 [==============================] - 12s 114ms/step - loss: 0.1656 - accuracy: 0.9338 - val_loss: 0.2386 - val_accuracy: 0.9094\n",
      "Epoch 91/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1493 - accuracy: 0.9344 - val_loss: 0.2117 - val_accuracy: 0.9167\n",
      "Epoch 92/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1555 - accuracy: 0.9278 - val_loss: 0.1885 - val_accuracy: 0.9372\n",
      "Epoch 93/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1580 - accuracy: 0.9332 - val_loss: 0.1831 - val_accuracy: 0.9227\n",
      "Epoch 94/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1647 - accuracy: 0.9287 - val_loss: 0.2409 - val_accuracy: 0.9034\n",
      "Epoch 95/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1680 - accuracy: 0.9244 - val_loss: 0.2027 - val_accuracy: 0.9227\n",
      "Epoch 96/250\n",
      "104/103 [==============================] - 12s 112ms/step - loss: 0.1712 - accuracy: 0.9199 - val_loss: 0.2362 - val_accuracy: 0.9094\n",
      "Epoch 97/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1537 - accuracy: 0.9317 - val_loss: 0.1853 - val_accuracy: 0.9312\n",
      "Epoch 98/250\n",
      "104/103 [==============================] - 12s 112ms/step - loss: 0.1668 - accuracy: 0.9311 - val_loss: 0.2386 - val_accuracy: 0.9155\n",
      "Epoch 99/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1521 - accuracy: 0.9326 - val_loss: 0.2671 - val_accuracy: 0.8973\n",
      "Epoch 100/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1478 - accuracy: 0.9374 - val_loss: 0.2200 - val_accuracy: 0.9143\n",
      "Epoch 101/250\n",
      "104/103 [==============================] - 12s 116ms/step - loss: 0.1700 - accuracy: 0.9317 - val_loss: 0.6388 - val_accuracy: 0.8007\n",
      "Epoch 102/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1872 - accuracy: 0.9299 - val_loss: 0.2432 - val_accuracy: 0.9082\n",
      "Epoch 103/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1641 - accuracy: 0.9275 - val_loss: 0.2086 - val_accuracy: 0.9155\n",
      "Epoch 104/250\n",
      "104/103 [==============================] - 12s 112ms/step - loss: 0.1518 - accuracy: 0.9329 - val_loss: 0.2239 - val_accuracy: 0.9227\n",
      "Epoch 105/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1772 - accuracy: 0.9278 - val_loss: 0.4381 - val_accuracy: 0.8720\n",
      "Epoch 106/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1759 - accuracy: 0.9275 - val_loss: 0.3001 - val_accuracy: 0.8877\n",
      "Epoch 107/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1523 - accuracy: 0.9353 - val_loss: 0.2215 - val_accuracy: 0.9191\n",
      "Epoch 108/250\n",
      "104/103 [==============================] - 12s 114ms/step - loss: 0.1512 - accuracy: 0.9338 - val_loss: 0.2412 - val_accuracy: 0.9143\n",
      "Epoch 109/250\n",
      "104/103 [==============================] - 12s 114ms/step - loss: 0.1557 - accuracy: 0.9299 - val_loss: 0.2333 - val_accuracy: 0.9094\n",
      "Epoch 110/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1504 - accuracy: 0.9308 - val_loss: 0.2030 - val_accuracy: 0.9251\n",
      "Epoch 111/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1693 - accuracy: 0.9311 - val_loss: 0.2837 - val_accuracy: 0.9046\n",
      "Epoch 112/250\n",
      "104/103 [==============================] - 12s 112ms/step - loss: 0.1749 - accuracy: 0.9220 - val_loss: 0.2271 - val_accuracy: 0.9167\n",
      "Epoch 113/250\n",
      "104/103 [==============================] - 12s 112ms/step - loss: 0.1460 - accuracy: 0.9365 - val_loss: 0.3647 - val_accuracy: 0.8599\n",
      "Epoch 114/250\n",
      "104/103 [==============================] - 12s 112ms/step - loss: 0.1642 - accuracy: 0.9305 - val_loss: 0.2212 - val_accuracy: 0.9239\n",
      "Epoch 115/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1611 - accuracy: 0.9320 - val_loss: 0.2358 - val_accuracy: 0.9143\n",
      "Epoch 116/250\n",
      "104/103 [==============================] - 12s 112ms/step - loss: 0.1428 - accuracy: 0.9383 - val_loss: 0.2182 - val_accuracy: 0.9203\n",
      "Epoch 117/250\n",
      "104/103 [==============================] - 12s 112ms/step - loss: 0.1525 - accuracy: 0.9350 - val_loss: 0.2871 - val_accuracy: 0.8949\n",
      "Epoch 118/250\n",
      "104/103 [==============================] - 12s 112ms/step - loss: 0.1612 - accuracy: 0.9293 - val_loss: 0.1854 - val_accuracy: 0.9324\n",
      "Epoch 119/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1543 - accuracy: 0.9362 - val_loss: 0.2330 - val_accuracy: 0.9118\n",
      "Epoch 120/250\n",
      "104/103 [==============================] - 12s 114ms/step - loss: 0.1480 - accuracy: 0.9387 - val_loss: 0.2461 - val_accuracy: 0.9058\n",
      "Epoch 121/250\n",
      "104/103 [==============================] - 12s 112ms/step - loss: 0.1536 - accuracy: 0.9323 - val_loss: 0.2221 - val_accuracy: 0.9287\n",
      "Epoch 122/250\n",
      "104/103 [==============================] - 12s 112ms/step - loss: 0.1587 - accuracy: 0.9341 - val_loss: 0.2359 - val_accuracy: 0.9155\n",
      "Epoch 123/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1421 - accuracy: 0.9347 - val_loss: 0.2080 - val_accuracy: 0.9203\n",
      "Epoch 124/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1518 - accuracy: 0.9371 - val_loss: 0.1905 - val_accuracy: 0.9251\n",
      "Epoch 125/250\n",
      "104/103 [==============================] - 12s 111ms/step - loss: 0.1394 - accuracy: 0.9365 - val_loss: 0.1956 - val_accuracy: 0.9287\n",
      "Epoch 126/250\n",
      "104/103 [==============================] - 12s 112ms/step - loss: 0.1460 - accuracy: 0.9341 - val_loss: 0.2500 - val_accuracy: 0.9046\n",
      "Epoch 127/250\n",
      "104/103 [==============================] - 12s 112ms/step - loss: 0.1578 - accuracy: 0.9314 - val_loss: 0.2211 - val_accuracy: 0.9130\n",
      "Epoch 128/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1427 - accuracy: 0.9356 - val_loss: 0.1790 - val_accuracy: 0.9360\n",
      "Epoch 129/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1404 - accuracy: 0.9408 - val_loss: 0.2800 - val_accuracy: 0.8901\n",
      "Epoch 130/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1401 - accuracy: 0.9374 - val_loss: 0.2424 - val_accuracy: 0.9046\n",
      "Epoch 131/250\n",
      "104/103 [==============================] - 11s 109ms/step - loss: 0.1563 - accuracy: 0.9350 - val_loss: 0.2288 - val_accuracy: 0.9227\n",
      "Epoch 132/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1621 - accuracy: 0.9317 - val_loss: 0.2271 - val_accuracy: 0.9215\n",
      "Epoch 133/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1549 - accuracy: 0.9380 - val_loss: 0.1978 - val_accuracy: 0.9287\n",
      "Epoch 134/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1607 - accuracy: 0.9290 - val_loss: 0.1965 - val_accuracy: 0.9336\n",
      "Epoch 135/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1386 - accuracy: 0.9362 - val_loss: 0.1918 - val_accuracy: 0.9312\n",
      "Epoch 136/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1399 - accuracy: 0.9420 - val_loss: 0.2224 - val_accuracy: 0.9227\n",
      "Epoch 137/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1579 - accuracy: 0.9387 - val_loss: 0.2168 - val_accuracy: 0.9118\n",
      "Epoch 138/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1433 - accuracy: 0.9338 - val_loss: 0.2574 - val_accuracy: 0.9094\n",
      "Epoch 139/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1449 - accuracy: 0.9329 - val_loss: 0.3320 - val_accuracy: 0.8732\n",
      "Epoch 140/250\n",
      "104/103 [==============================] - 13s 122ms/step - loss: 0.1988 - accuracy: 0.9205 - val_loss: 0.3978 - val_accuracy: 0.8527\n",
      "Epoch 141/250\n",
      "104/103 [==============================] - 12s 119ms/step - loss: 0.1511 - accuracy: 0.9359 - val_loss: 0.1968 - val_accuracy: 0.9300\n",
      "Epoch 142/250\n",
      "104/103 [==============================] - 13s 126ms/step - loss: 0.1569 - accuracy: 0.9323 - val_loss: 0.2069 - val_accuracy: 0.9324\n",
      "Epoch 143/250\n",
      "104/103 [==============================] - 12s 119ms/step - loss: 0.1397 - accuracy: 0.9380 - val_loss: 0.2264 - val_accuracy: 0.9167\n",
      "Epoch 144/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1454 - accuracy: 0.9365 - val_loss: 0.2002 - val_accuracy: 0.9263\n",
      "Epoch 145/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1543 - accuracy: 0.9359 - val_loss: 0.2252 - val_accuracy: 0.9239\n",
      "Epoch 146/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1534 - accuracy: 0.9335 - val_loss: 0.1668 - val_accuracy: 0.9396\n",
      "Epoch 147/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1548 - accuracy: 0.9347 - val_loss: 0.2246 - val_accuracy: 0.9179\n",
      "Epoch 148/250\n",
      "104/103 [==============================] - 12s 111ms/step - loss: 0.1297 - accuracy: 0.9399 - val_loss: 0.2575 - val_accuracy: 0.9010\n",
      "Epoch 149/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1625 - accuracy: 0.9314 - val_loss: 0.2192 - val_accuracy: 0.9275\n",
      "Epoch 150/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1373 - accuracy: 0.9393 - val_loss: 0.1992 - val_accuracy: 0.9227\n",
      "Epoch 151/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1489 - accuracy: 0.9347 - val_loss: 0.2123 - val_accuracy: 0.9239\n",
      "Epoch 152/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1499 - accuracy: 0.9359 - val_loss: 0.2232 - val_accuracy: 0.9215\n",
      "Epoch 153/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1415 - accuracy: 0.9371 - val_loss: 0.2104 - val_accuracy: 0.9227\n",
      "Epoch 154/250\n",
      "104/103 [==============================] - 11s 109ms/step - loss: 0.1638 - accuracy: 0.9278 - val_loss: 0.2311 - val_accuracy: 0.9215\n",
      "Epoch 155/250\n",
      "104/103 [==============================] - 11s 109ms/step - loss: 0.1423 - accuracy: 0.9405 - val_loss: 0.2642 - val_accuracy: 0.8973\n",
      "Epoch 156/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1357 - accuracy: 0.9383 - val_loss: 0.2877 - val_accuracy: 0.8901\n",
      "Epoch 157/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1989 - accuracy: 0.9184 - val_loss: 0.2650 - val_accuracy: 0.9058\n",
      "Epoch 158/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1358 - accuracy: 0.9441 - val_loss: 0.2312 - val_accuracy: 0.9167\n",
      "Epoch 159/250\n",
      "104/103 [==============================] - 12s 111ms/step - loss: 0.1480 - accuracy: 0.9329 - val_loss: 0.2209 - val_accuracy: 0.9143\n",
      "Epoch 160/250\n",
      "104/103 [==============================] - 11s 109ms/step - loss: 0.1346 - accuracy: 0.9380 - val_loss: 0.1945 - val_accuracy: 0.9360\n",
      "Epoch 161/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1463 - accuracy: 0.9377 - val_loss: 0.2281 - val_accuracy: 0.9179\n",
      "Epoch 162/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1479 - accuracy: 0.9344 - val_loss: 0.1965 - val_accuracy: 0.9287\n",
      "Epoch 163/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1302 - accuracy: 0.9432 - val_loss: 0.2299 - val_accuracy: 0.9058\n",
      "Epoch 164/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1564 - accuracy: 0.9393 - val_loss: 0.2747 - val_accuracy: 0.8949\n",
      "Epoch 165/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1316 - accuracy: 0.9414 - val_loss: 0.2782 - val_accuracy: 0.9094\n",
      "Epoch 166/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1808 - accuracy: 0.9272 - val_loss: 0.1984 - val_accuracy: 0.9263\n",
      "Epoch 167/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/103 [==============================] - 11s 109ms/step - loss: 0.1535 - accuracy: 0.9368 - val_loss: 0.2988 - val_accuracy: 0.8780\n",
      "Epoch 168/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1481 - accuracy: 0.9365 - val_loss: 0.1975 - val_accuracy: 0.9287\n",
      "Epoch 169/250\n",
      "104/103 [==============================] - 12s 112ms/step - loss: 0.1274 - accuracy: 0.9435 - val_loss: 0.2197 - val_accuracy: 0.9167\n",
      "Epoch 170/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1262 - accuracy: 0.9432 - val_loss: 0.2066 - val_accuracy: 0.9263\n",
      "Epoch 171/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.2068 - accuracy: 0.9251 - val_loss: 0.2726 - val_accuracy: 0.8973\n",
      "Epoch 172/250\n",
      "104/103 [==============================] - 11s 109ms/step - loss: 0.1427 - accuracy: 0.9426 - val_loss: 0.2395 - val_accuracy: 0.9203\n",
      "Epoch 173/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1574 - accuracy: 0.9275 - val_loss: 0.2970 - val_accuracy: 0.9167\n",
      "Epoch 174/250\n",
      "104/103 [==============================] - 12s 116ms/step - loss: 0.1462 - accuracy: 0.9411 - val_loss: 0.2226 - val_accuracy: 0.9203\n",
      "Epoch 175/250\n",
      "104/103 [==============================] - 12s 116ms/step - loss: 0.1293 - accuracy: 0.9450 - val_loss: 0.1895 - val_accuracy: 0.9263\n",
      "Epoch 176/250\n",
      "104/103 [==============================] - 12s 118ms/step - loss: 0.1329 - accuracy: 0.9438 - val_loss: 0.2568 - val_accuracy: 0.8973\n",
      "Epoch 177/250\n",
      "104/103 [==============================] - 13s 121ms/step - loss: 0.1216 - accuracy: 0.9483 - val_loss: 0.2091 - val_accuracy: 0.9263\n",
      "Epoch 178/250\n",
      "104/103 [==============================] - 12s 119ms/step - loss: 0.1657 - accuracy: 0.9326 - val_loss: 0.2683 - val_accuracy: 0.9022\n",
      "Epoch 179/250\n",
      "104/103 [==============================] - 12s 115ms/step - loss: 0.1401 - accuracy: 0.9390 - val_loss: 0.2117 - val_accuracy: 0.9191\n",
      "Epoch 180/250\n",
      "104/103 [==============================] - 12s 120ms/step - loss: 0.1376 - accuracy: 0.9399 - val_loss: 0.2343 - val_accuracy: 0.9155\n",
      "Epoch 181/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1556 - accuracy: 0.9356 - val_loss: 0.2518 - val_accuracy: 0.9058\n",
      "Epoch 182/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1569 - accuracy: 0.9359 - val_loss: 0.2443 - val_accuracy: 0.9022\n",
      "Epoch 183/250\n",
      "104/103 [==============================] - 12s 114ms/step - loss: 0.1427 - accuracy: 0.9387 - val_loss: 0.2475 - val_accuracy: 0.9167\n",
      "Epoch 184/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1347 - accuracy: 0.9423 - val_loss: 0.2510 - val_accuracy: 0.9058\n",
      "Epoch 185/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1291 - accuracy: 0.9411 - val_loss: 0.2525 - val_accuracy: 0.9010\n",
      "Epoch 186/250\n",
      "104/103 [==============================] - 12s 114ms/step - loss: 0.1358 - accuracy: 0.9393 - val_loss: 0.2126 - val_accuracy: 0.9203\n",
      "Epoch 187/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1708 - accuracy: 0.9305 - val_loss: 0.2298 - val_accuracy: 0.9106\n",
      "Epoch 188/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1462 - accuracy: 0.9371 - val_loss: 0.2968 - val_accuracy: 0.8973\n",
      "Epoch 189/250\n",
      "104/103 [==============================] - 12s 114ms/step - loss: 0.1414 - accuracy: 0.9374 - val_loss: 0.2625 - val_accuracy: 0.9082\n",
      "Epoch 190/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1390 - accuracy: 0.9420 - val_loss: 0.3011 - val_accuracy: 0.9046\n",
      "Epoch 191/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1369 - accuracy: 0.9420 - val_loss: 0.2824 - val_accuracy: 0.9058\n",
      "Epoch 192/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1310 - accuracy: 0.9453 - val_loss: 0.2106 - val_accuracy: 0.9155\n",
      "Epoch 193/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1457 - accuracy: 0.9344 - val_loss: 0.2387 - val_accuracy: 0.9022\n",
      "Epoch 194/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1594 - accuracy: 0.9350 - val_loss: 0.3096 - val_accuracy: 0.8841\n",
      "Epoch 195/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1415 - accuracy: 0.9380 - val_loss: 0.2337 - val_accuracy: 0.9118\n",
      "Epoch 196/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1306 - accuracy: 0.9459 - val_loss: 0.2362 - val_accuracy: 0.9130\n",
      "Epoch 197/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1513 - accuracy: 0.9408 - val_loss: 0.2359 - val_accuracy: 0.9155\n",
      "Epoch 198/250\n",
      "104/103 [==============================] - 12s 114ms/step - loss: 0.1316 - accuracy: 0.9414 - val_loss: 0.3558 - val_accuracy: 0.8539\n",
      "Epoch 199/250\n",
      "104/103 [==============================] - 12s 114ms/step - loss: 0.1416 - accuracy: 0.9390 - val_loss: 0.2328 - val_accuracy: 0.9203\n",
      "Epoch 200/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.2310 - accuracy: 0.9121 - val_loss: 0.3902 - val_accuracy: 0.8575\n",
      "Epoch 201/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1490 - accuracy: 0.9377 - val_loss: 0.2448 - val_accuracy: 0.8973\n",
      "Epoch 202/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1277 - accuracy: 0.9447 - val_loss: 0.2102 - val_accuracy: 0.9203\n",
      "Epoch 203/250\n",
      "104/103 [==============================] - 12s 116ms/step - loss: 0.1440 - accuracy: 0.9387 - val_loss: 0.2567 - val_accuracy: 0.9034\n",
      "Epoch 204/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1406 - accuracy: 0.9408 - val_loss: 0.2364 - val_accuracy: 0.9130\n",
      "Epoch 205/250\n",
      "104/103 [==============================] - 12s 114ms/step - loss: 0.1385 - accuracy: 0.9390 - val_loss: 0.2324 - val_accuracy: 0.9143\n",
      "Epoch 206/250\n",
      "104/103 [==============================] - 12s 114ms/step - loss: 0.1424 - accuracy: 0.9371 - val_loss: 0.2652 - val_accuracy: 0.9022\n",
      "Epoch 207/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1311 - accuracy: 0.9411 - val_loss: 0.3001 - val_accuracy: 0.8961\n",
      "Epoch 208/250\n",
      "104/103 [==============================] - 12s 114ms/step - loss: 0.1413 - accuracy: 0.9408 - val_loss: 0.2597 - val_accuracy: 0.9094\n",
      "Epoch 209/250\n",
      "104/103 [==============================] - 12s 114ms/step - loss: 0.1489 - accuracy: 0.9380 - val_loss: 0.2206 - val_accuracy: 0.9143\n",
      "Epoch 210/250\n",
      "104/103 [==============================] - 12s 116ms/step - loss: 0.1442 - accuracy: 0.9408 - val_loss: 0.3536 - val_accuracy: 0.8853\n",
      "Epoch 211/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1528 - accuracy: 0.9353 - val_loss: 0.2842 - val_accuracy: 0.8973\n",
      "Epoch 212/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1459 - accuracy: 0.9368 - val_loss: 0.2674 - val_accuracy: 0.8986\n",
      "Epoch 213/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1340 - accuracy: 0.9399 - val_loss: 0.2800 - val_accuracy: 0.8949\n",
      "Epoch 214/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1452 - accuracy: 0.9317 - val_loss: 0.2830 - val_accuracy: 0.8973\n",
      "Epoch 215/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1421 - accuracy: 0.9408 - val_loss: 0.2595 - val_accuracy: 0.8998\n",
      "Epoch 216/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1357 - accuracy: 0.9417 - val_loss: 0.3019 - val_accuracy: 0.8865\n",
      "Epoch 217/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1430 - accuracy: 0.9399 - val_loss: 0.2502 - val_accuracy: 0.9022\n",
      "Epoch 218/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1342 - accuracy: 0.9393 - val_loss: 0.2937 - val_accuracy: 0.8901\n",
      "Epoch 219/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1313 - accuracy: 0.9390 - val_loss: 0.2799 - val_accuracy: 0.8829\n",
      "Epoch 220/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1505 - accuracy: 0.9362 - val_loss: 0.2211 - val_accuracy: 0.9155\n",
      "Epoch 221/250\n",
      "104/103 [==============================] - 12s 115ms/step - loss: 0.1368 - accuracy: 0.9423 - val_loss: 0.2897 - val_accuracy: 0.8925\n",
      "Epoch 222/250\n",
      "104/103 [==============================] - 12s 112ms/step - loss: 0.1501 - accuracy: 0.9383 - val_loss: 0.2588 - val_accuracy: 0.8973\n",
      "Epoch 223/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1296 - accuracy: 0.9441 - val_loss: 0.2666 - val_accuracy: 0.8998\n",
      "Epoch 224/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1448 - accuracy: 0.9411 - val_loss: 0.2705 - val_accuracy: 0.8925\n",
      "Epoch 225/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1393 - accuracy: 0.9383 - val_loss: 0.2732 - val_accuracy: 0.9046\n",
      "Epoch 226/250\n",
      "104/103 [==============================] - 12s 112ms/step - loss: 0.1695 - accuracy: 0.9308 - val_loss: 0.2664 - val_accuracy: 0.9070\n",
      "Epoch 227/250\n",
      "104/103 [==============================] - 12s 112ms/step - loss: 0.1405 - accuracy: 0.9390 - val_loss: 0.3292 - val_accuracy: 0.8659\n",
      "Epoch 228/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1237 - accuracy: 0.9465 - val_loss: 0.2396 - val_accuracy: 0.9106\n",
      "Epoch 229/250\n",
      "104/103 [==============================] - 12s 113ms/step - loss: 0.1281 - accuracy: 0.9462 - val_loss: 0.2689 - val_accuracy: 0.9010\n",
      "Epoch 230/250\n",
      "104/103 [==============================] - 12s 112ms/step - loss: 0.1328 - accuracy: 0.9417 - val_loss: 0.1878 - val_accuracy: 0.9287\n",
      "Epoch 231/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1473 - accuracy: 0.9371 - val_loss: 0.2571 - val_accuracy: 0.9130\n",
      "Epoch 232/250\n",
      "104/103 [==============================] - 11s 109ms/step - loss: 0.1547 - accuracy: 0.9387 - val_loss: 0.2482 - val_accuracy: 0.9118\n",
      "Epoch 233/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1353 - accuracy: 0.9390 - val_loss: 0.3038 - val_accuracy: 0.8973\n",
      "Epoch 234/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1189 - accuracy: 0.9417 - val_loss: 0.2667 - val_accuracy: 0.9046\n",
      "Epoch 235/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1188 - accuracy: 0.9456 - val_loss: 0.2219 - val_accuracy: 0.9203\n",
      "Epoch 236/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1316 - accuracy: 0.9435 - val_loss: 0.3231 - val_accuracy: 0.8925\n",
      "Epoch 237/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1404 - accuracy: 0.9393 - val_loss: 0.2747 - val_accuracy: 0.9022\n",
      "Epoch 238/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1285 - accuracy: 0.9414 - val_loss: 0.2562 - val_accuracy: 0.9094\n",
      "Epoch 239/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1330 - accuracy: 0.9390 - val_loss: 0.2887 - val_accuracy: 0.8986\n",
      "Epoch 240/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1318 - accuracy: 0.9465 - val_loss: 0.2795 - val_accuracy: 0.9034\n",
      "Epoch 241/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1387 - accuracy: 0.9399 - val_loss: 0.3511 - val_accuracy: 0.8829\n",
      "Epoch 242/250\n",
      "104/103 [==============================] - 12s 111ms/step - loss: 0.1339 - accuracy: 0.9374 - val_loss: 0.2688 - val_accuracy: 0.9010\n",
      "Epoch 243/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1256 - accuracy: 0.9441 - val_loss: 0.2771 - val_accuracy: 0.8877\n",
      "Epoch 244/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1489 - accuracy: 0.9399 - val_loss: 0.3166 - val_accuracy: 0.9046\n",
      "Epoch 245/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1437 - accuracy: 0.9377 - val_loss: 0.2811 - val_accuracy: 0.8986\n",
      "Epoch 246/250\n",
      "104/103 [==============================] - 11s 109ms/step - loss: 0.1330 - accuracy: 0.9390 - val_loss: 0.2433 - val_accuracy: 0.9082\n",
      "Epoch 247/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1268 - accuracy: 0.9420 - val_loss: 0.3427 - val_accuracy: 0.8865\n",
      "Epoch 248/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1477 - accuracy: 0.9353 - val_loss: 0.3326 - val_accuracy: 0.8792\n",
      "Epoch 249/250\n",
      "104/103 [==============================] - 11s 110ms/step - loss: 0.1341 - accuracy: 0.9387 - val_loss: 0.2293 - val_accuracy: 0.9167\n",
      "Epoch 250/250\n",
      "104/103 [==============================] - 12s 111ms/step - loss: 0.1318 - accuracy: 0.9429 - val_loss: 0.3043 - val_accuracy: 0.9070\n"
     ]
    }
   ],
   "source": [
    "train_model_test  = model2.fit_generator(image_generator.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                        epochs=250,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        steps_per_epoch=len(X_train)/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kekay\\anaconda3\\lib\\site-packages\\plotly\\tools.py:465: DeprecationWarning:\n",
      "\n",
      "plotly.tools.make_subplots is deprecated, please use plotly.subplots.make_subplots instead\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "marker": {
          "color": "Green"
         },
         "mode": "markers+lines",
         "name": "Training accuracy",
         "text": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12",
          "13",
          "14",
          "15",
          "16",
          "17",
          "18",
          "19",
          "20",
          "21",
          "22",
          "23",
          "24",
          "25",
          "26",
          "27",
          "28",
          "29",
          "30",
          "31",
          "32",
          "33",
          "34",
          "35",
          "36",
          "37",
          "38",
          "39",
          "40",
          "41",
          "42",
          "43",
          "44",
          "45",
          "46",
          "47",
          "48",
          "49",
          "50",
          "51",
          "52",
          "53",
          "54",
          "55",
          "56",
          "57",
          "58",
          "59",
          "60",
          "61",
          "62",
          "63",
          "64",
          "65",
          "66",
          "67",
          "68",
          "69",
          "70",
          "71",
          "72",
          "73",
          "74",
          "75",
          "76",
          "77",
          "78",
          "79",
          "80",
          "81",
          "82",
          "83",
          "84",
          "85",
          "86",
          "87",
          "88",
          "89",
          "90",
          "91",
          "92",
          "93",
          "94",
          "95",
          "96",
          "97",
          "98",
          "99",
          "100",
          "101",
          "102",
          "103",
          "104",
          "105",
          "106",
          "107",
          "108",
          "109",
          "110",
          "111",
          "112",
          "113",
          "114",
          "115",
          "116",
          "117",
          "118",
          "119",
          "120",
          "121",
          "122",
          "123",
          "124",
          "125",
          "126",
          "127",
          "128",
          "129",
          "130",
          "131",
          "132",
          "133",
          "134",
          "135",
          "136",
          "137",
          "138",
          "139",
          "140",
          "141",
          "142",
          "143",
          "144",
          "145",
          "146",
          "147",
          "148",
          "149",
          "150",
          "151",
          "152",
          "153",
          "154",
          "155",
          "156",
          "157",
          "158",
          "159",
          "160",
          "161",
          "162",
          "163",
          "164",
          "165",
          "166",
          "167",
          "168",
          "169",
          "170",
          "171",
          "172",
          "173",
          "174",
          "175",
          "176",
          "177",
          "178",
          "179",
          "180",
          "181",
          "182",
          "183",
          "184",
          "185",
          "186",
          "187",
          "188",
          "189",
          "190",
          "191",
          "192",
          "193",
          "194",
          "195",
          "196",
          "197",
          "198",
          "199",
          "200",
          "201",
          "202",
          "203",
          "204",
          "205",
          "206",
          "207",
          "208",
          "209",
          "210",
          "211",
          "212",
          "213",
          "214",
          "215",
          "216",
          "217",
          "218",
          "219",
          "220",
          "221",
          "222",
          "223",
          "224",
          "225",
          "226",
          "227",
          "228",
          "229",
          "230",
          "231",
          "232",
          "233",
          "234",
          "235",
          "236",
          "237",
          "238",
          "239",
          "240",
          "241",
          "242",
          "243",
          "244",
          "245",
          "246",
          "247",
          "248",
          "249",
          "250"
         ],
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250
         ],
         "xaxis": "x",
         "y": [
          0.884255051612854,
          0.8933212161064148,
          0.8766999244689941,
          0.8945300579071045,
          0.8851616978645325,
          0.8812329769134521,
          0.895436704158783,
          0.895436704158783,
          0.9005742073059082,
          0.8863704800605774,
          0.8824418187141418,
          0.8921124339103699,
          0.9099425673484802,
          0.899969756603241,
          0.9008764028549194,
          0.8881837129592896,
          0.9029918313026428,
          0.9072227478027344,
          0.8990631699562073,
          0.9066182971000671,
          0.9069204926490784,
          0.9008764028549194,
          0.9023874402046204,
          0.9075249433517456,
          0.9045028686523438,
          0.8981565237045288,
          0.909640371799469,
          0.9132668375968933,
          0.9117558002471924,
          0.9138712882995605,
          0.9054095149040222,
          0.9150800704956055,
          0.9102447628974915,
          0.9105470180511475,
          0.9108492136001587,
          0.9147778749465942,
          0.8969477415084839,
          0.9190087914466858,
          0.9069204926490784,
          0.9023874402046204,
          0.9226352572441101,
          0.9156845211982727,
          0.9214264154434204,
          0.9226352572441101,
          0.9129646420478821,
          0.9247506856918335,
          0.9126624464988708,
          0.9220308065414429,
          0.9229374527931213,
          0.9211242198944092,
          0.9199153780937195,
          0.9093381762504578,
          0.9184043407440186,
          0.9214264154434204,
          0.9205197691917419,
          0.9168933033943176,
          0.9153822660446167,
          0.9247506856918335,
          0.9268661141395569,
          0.9268661141395569,
          0.9310970306396484,
          0.9190087914466858,
          0.9274705052375793,
          0.9196131825447083,
          0.9247506856918335,
          0.9196131825447083,
          0.9132668375968933,
          0.93019038438797,
          0.9220308065414429,
          0.9205197691917419,
          0.9295859932899475,
          0.9259595274925232,
          0.9235418438911438,
          0.9187065362930298,
          0.9292837977409363,
          0.9244484901428223,
          0.9177999496459961,
          0.9307947754859924,
          0.928679347038269,
          0.9232396483421326,
          0.9223330020904541,
          0.9268661141395569,
          0.9262617230415344,
          0.9326080679893494,
          0.9256572723388672,
          0.9199153780937195,
          0.924146294593811,
          0.9262617230415344,
          0.9244484901428223,
          0.9338168501853943,
          0.9344213008880615,
          0.9277727603912354,
          0.9332124590873718,
          0.928679347038269,
          0.9244484901428223,
          0.9199153780937195,
          0.9317014217376709,
          0.9310970306396484,
          0.9326080679893494,
          0.9374433159828186,
          0.9317014217376709,
          0.9298881888389587,
          0.9274705052375793,
          0.9329102635383606,
          0.9277727603912354,
          0.9274705052375793,
          0.9353278875350952,
          0.9338168501853943,
          0.9298881888389587,
          0.9307947754859924,
          0.9310970306396484,
          0.9220308065414429,
          0.9365367293357849,
          0.9304925799369812,
          0.9320036172866821,
          0.9383499622344971,
          0.935025691986084,
          0.9292837977409363,
          0.9362345337867737,
          0.9386521577835083,
          0.9323058128356934,
          0.9341190457344055,
          0.9347234964370728,
          0.9371411204338074,
          0.9365367293357849,
          0.9341190457344055,
          0.9313992261886597,
          0.9356300830841064,
          0.9407675862312317,
          0.9374433159828186,
          0.935025691986084,
          0.9317014217376709,
          0.9380477666854858,
          0.9289815425872803,
          0.9362345337867737,
          0.9419764280319214,
          0.9386521577835083,
          0.9338168501853943,
          0.9329102635383606,
          0.9205197691917419,
          0.9359322786331177,
          0.9323058128356934,
          0.9380477666854858,
          0.9365367293357849,
          0.9359322786331177,
          0.9335146546363831,
          0.9347234964370728,
          0.939860999584198,
          0.9313992261886597,
          0.9392565488815308,
          0.9347234964370728,
          0.9359322786331177,
          0.9371411204338074,
          0.9277727603912354,
          0.9404653906822205,
          0.9383499622344971,
          0.9184043407440186,
          0.9440918564796448,
          0.9329102635383606,
          0.9380477666854858,
          0.9377455711364746,
          0.9344213008880615,
          0.9431852698326111,
          0.9392565488815308,
          0.9413720369338989,
          0.9271683096885681,
          0.9368389248847961,
          0.9365367293357849,
          0.9434874653816223,
          0.9431852698326111,
          0.9250528812408447,
          0.9425808191299438,
          0.9274705052375793,
          0.9410697817802429,
          0.9449985027313232,
          0.9437896609306335,
          0.9483227729797363,
          0.9326080679893494,
          0.9389543533325195,
          0.939860999584198,
          0.9356300830841064,
          0.9359322786331177,
          0.9386521577835083,
          0.9422786235809326,
          0.9410697817802429,
          0.9392565488815308,
          0.9304925799369812,
          0.9371411204338074,
          0.9374433159828186,
          0.9419764280319214,
          0.9419764280319214,
          0.9453006982803345,
          0.9344213008880615,
          0.935025691986084,
          0.9380477666854858,
          0.9459050893783569,
          0.9407675862312317,
          0.9413720369338989,
          0.9389543533325195,
          0.9120579957962036,
          0.9377455711364746,
          0.944696307182312,
          0.9386521577835083,
          0.9407675862312317,
          0.9389543533325195,
          0.9371411204338074,
          0.9410697817802429,
          0.9407675862312317,
          0.9380477666854858,
          0.9407675862312317,
          0.9353278875350952,
          0.9368389248847961,
          0.939860999584198,
          0.9317014217376709,
          0.9407675862312317,
          0.9416742324829102,
          0.939860999584198,
          0.9392565488815308,
          0.9389543533325195,
          0.9362345337867737,
          0.9422786235809326,
          0.9383499622344971,
          0.9440918564796448,
          0.9410697817802429,
          0.9383499622344971,
          0.9307947754859924,
          0.9389543533325195,
          0.9465095400810242,
          0.9462072849273682,
          0.9416742324829102,
          0.9371411204338074,
          0.9386521577835083,
          0.9389543533325195,
          0.9416742324829102,
          0.9456028938293457,
          0.9434874653816223,
          0.9392565488815308,
          0.9413720369338989,
          0.9389543533325195,
          0.9465095400810242,
          0.939860999584198,
          0.9374433159828186,
          0.9440918564796448,
          0.939860999584198,
          0.9377455711364746,
          0.9389543533325195,
          0.9419764280319214,
          0.9353278875350952,
          0.9386521577835083,
          0.9428830742835999
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "Red"
         },
         "mode": "markers+lines",
         "name": "Validation accuracy",
         "text": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12",
          "13",
          "14",
          "15",
          "16",
          "17",
          "18",
          "19",
          "20",
          "21",
          "22",
          "23",
          "24",
          "25",
          "26",
          "27",
          "28",
          "29",
          "30",
          "31",
          "32",
          "33",
          "34",
          "35",
          "36",
          "37",
          "38",
          "39",
          "40",
          "41",
          "42",
          "43",
          "44",
          "45",
          "46",
          "47",
          "48",
          "49",
          "50",
          "51",
          "52",
          "53",
          "54",
          "55",
          "56",
          "57",
          "58",
          "59",
          "60",
          "61",
          "62",
          "63",
          "64",
          "65",
          "66",
          "67",
          "68",
          "69",
          "70",
          "71",
          "72",
          "73",
          "74",
          "75",
          "76",
          "77",
          "78",
          "79",
          "80",
          "81",
          "82",
          "83",
          "84",
          "85",
          "86",
          "87",
          "88",
          "89",
          "90",
          "91",
          "92",
          "93",
          "94",
          "95",
          "96",
          "97",
          "98",
          "99",
          "100",
          "101",
          "102",
          "103",
          "104",
          "105",
          "106",
          "107",
          "108",
          "109",
          "110",
          "111",
          "112",
          "113",
          "114",
          "115",
          "116",
          "117",
          "118",
          "119",
          "120",
          "121",
          "122",
          "123",
          "124",
          "125",
          "126",
          "127",
          "128",
          "129",
          "130",
          "131",
          "132",
          "133",
          "134",
          "135",
          "136",
          "137",
          "138",
          "139",
          "140",
          "141",
          "142",
          "143",
          "144",
          "145",
          "146",
          "147",
          "148",
          "149",
          "150",
          "151",
          "152",
          "153",
          "154",
          "155",
          "156",
          "157",
          "158",
          "159",
          "160",
          "161",
          "162",
          "163",
          "164",
          "165",
          "166",
          "167",
          "168",
          "169",
          "170",
          "171",
          "172",
          "173",
          "174",
          "175",
          "176",
          "177",
          "178",
          "179",
          "180",
          "181",
          "182",
          "183",
          "184",
          "185",
          "186",
          "187",
          "188",
          "189",
          "190",
          "191",
          "192",
          "193",
          "194",
          "195",
          "196",
          "197",
          "198",
          "199",
          "200",
          "201",
          "202",
          "203",
          "204",
          "205",
          "206",
          "207",
          "208",
          "209",
          "210",
          "211",
          "212",
          "213",
          "214",
          "215",
          "216",
          "217",
          "218",
          "219",
          "220",
          "221",
          "222",
          "223",
          "224",
          "225",
          "226",
          "227",
          "228",
          "229",
          "230",
          "231",
          "232",
          "233",
          "234",
          "235",
          "236",
          "237",
          "238",
          "239",
          "240",
          "241",
          "242",
          "243",
          "244",
          "245",
          "246",
          "247",
          "248",
          "249",
          "250"
         ],
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250
         ],
         "xaxis": "x",
         "y": [
          0.8852657079696655,
          0.8780193328857422,
          0.8961352705955505,
          0.8792270421981812,
          0.8599033951759338,
          0.8369565010070801,
          0.8925120830535889,
          0.9094203114509583,
          0.8756038546562195,
          0.8888888955116272,
          0.9033816456794739,
          0.9033816456794739,
          0.8756038546562195,
          0.8695651888847351,
          0.8997584581375122,
          0.8550724387168884,
          0.8719806671142578,
          0.8888888955116272,
          0.8756038546562195,
          0.8949275612831116,
          0.8816425204277039,
          0.8840579986572266,
          0.8574879169464111,
          0.8490338325500488,
          0.8671497702598572,
          0.8768116235733032,
          0.8985507488250732,
          0.8285024166107178,
          0.8949275612831116,
          0.8961352705955505,
          0.8876811861991882,
          0.8780193328857422,
          0.8768116235733032,
          0.9045893549919128,
          0.9009661674499512,
          0.8864734172821045,
          0.8985507488250732,
          0.9021739363670349,
          0.8888888955116272,
          0.9082125425338745,
          0.9142512083053589,
          0.9021739363670349,
          0.8913043737411499,
          0.9106280207633972,
          0.8913043737411499,
          0.9021739363670349,
          0.9154589176177979,
          0.8900966048240662,
          0.9057971239089966,
          0.8840579986572266,
          0.8900966048240662,
          0.8852657079696655,
          0.9045893549919128,
          0.8804348111152649,
          0.9057971239089966,
          0.9070048332214355,
          0.8719806671142578,
          0.9021739363670349,
          0.9166666865348816,
          0.9106280207633972,
          0.8925120830535889,
          0.9202898740768433,
          0.8768116235733032,
          0.9178743958473206,
          0.9070048332214355,
          0.9106280207633972,
          0.8985507488250732,
          0.8937197923660278,
          0.9130434989929199,
          0.9154589176177979,
          0.9094203114509583,
          0.9021739363670349,
          0.8840579986572266,
          0.9142512083053589,
          0.9239130616188049,
          0.9118357300758362,
          0.9033816456794739,
          0.9070048332214355,
          0.9202898740768433,
          0.9178743958473206,
          0.8985507488250732,
          0.9009661674499512,
          0.9142512083053589,
          0.9396135210990906,
          0.9190821051597595,
          0.9214975833892822,
          0.9057971239089966,
          0.9154589176177979,
          0.9251207709312439,
          0.9094203114509583,
          0.9166666865348816,
          0.9371980428695679,
          0.9227052927017212,
          0.9033816456794739,
          0.9227052927017212,
          0.9094203114509583,
          0.9311594367027283,
          0.9154589176177979,
          0.8973429799079895,
          0.9142512083053589,
          0.8007246255874634,
          0.9082125425338745,
          0.9154589176177979,
          0.9227052927017212,
          0.8719806671142578,
          0.8876811861991882,
          0.9190821051597595,
          0.9142512083053589,
          0.9094203114509583,
          0.9251207709312439,
          0.9045893549919128,
          0.9166666865348816,
          0.8599033951759338,
          0.9239130616188049,
          0.9142512083053589,
          0.9202898740768433,
          0.8949275612831116,
          0.9323671460151672,
          0.9118357300758362,
          0.9057971239089966,
          0.9287439584732056,
          0.9154589176177979,
          0.9202898740768433,
          0.9251207709312439,
          0.9287439584732056,
          0.9045893549919128,
          0.9130434989929199,
          0.9359903335571289,
          0.8900966048240662,
          0.9045893549919128,
          0.9227052927017212,
          0.9214975833892822,
          0.9287439584732056,
          0.9335748553276062,
          0.9311594367027283,
          0.9227052927017212,
          0.9118357300758362,
          0.9094203114509583,
          0.8731883764266968,
          0.8526570200920105,
          0.9299516677856445,
          0.9323671460151672,
          0.9166666865348816,
          0.9263284802436829,
          0.9239130616188049,
          0.9396135210990906,
          0.9178743958473206,
          0.9009661674499512,
          0.9275362491607666,
          0.9227052927017212,
          0.9239130616188049,
          0.9214975833892822,
          0.9227052927017212,
          0.9214975833892822,
          0.8973429799079895,
          0.8900966048240662,
          0.9057971239089966,
          0.9166666865348816,
          0.9142512083053589,
          0.9359903335571289,
          0.9178743958473206,
          0.9287439584732056,
          0.9057971239089966,
          0.8949275612831116,
          0.9094203114509583,
          0.9263284802436829,
          0.8780193328857422,
          0.9287439584732056,
          0.9166666865348816,
          0.9263284802436829,
          0.8973429799079895,
          0.9202898740768433,
          0.9166666865348816,
          0.9202898740768433,
          0.9263284802436829,
          0.8973429799079895,
          0.9263284802436829,
          0.9021739363670349,
          0.9190821051597595,
          0.9154589176177979,
          0.9057971239089966,
          0.9021739363670349,
          0.9166666865348816,
          0.9057971239089966,
          0.9009661674499512,
          0.9202898740768433,
          0.9106280207633972,
          0.8973429799079895,
          0.9082125425338745,
          0.9045893549919128,
          0.9057971239089966,
          0.9154589176177979,
          0.9021739363670349,
          0.8840579986572266,
          0.9118357300758362,
          0.9130434989929199,
          0.9154589176177979,
          0.8538647294044495,
          0.9202898740768433,
          0.8574879169464111,
          0.8973429799079895,
          0.9202898740768433,
          0.9033816456794739,
          0.9130434989929199,
          0.9142512083053589,
          0.9021739363670349,
          0.8961352705955505,
          0.9094203114509583,
          0.9142512083053589,
          0.8852657079696655,
          0.8973429799079895,
          0.8985507488250732,
          0.8949275612831116,
          0.8973429799079895,
          0.8997584581375122,
          0.8864734172821045,
          0.9021739363670349,
          0.8900966048240662,
          0.8828502297401428,
          0.9154589176177979,
          0.8925120830535889,
          0.8973429799079895,
          0.8997584581375122,
          0.8925120830535889,
          0.9045893549919128,
          0.9070048332214355,
          0.8659420013427734,
          0.9106280207633972,
          0.9009661674499512,
          0.9287439584732056,
          0.9130434989929199,
          0.9118357300758362,
          0.8973429799079895,
          0.9045893549919128,
          0.9202898740768433,
          0.8925120830535889,
          0.9021739363670349,
          0.9094203114509583,
          0.8985507488250732,
          0.9033816456794739,
          0.8828502297401428,
          0.9009661674499512,
          0.8876811861991882,
          0.9045893549919128,
          0.8985507488250732,
          0.9082125425338745,
          0.8864734172821045,
          0.8792270421981812,
          0.9166666865348816,
          0.9070048332214355
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "Blue"
         },
         "mode": "markers+lines",
         "name": "Training loss",
         "text": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12",
          "13",
          "14",
          "15",
          "16",
          "17",
          "18",
          "19",
          "20",
          "21",
          "22",
          "23",
          "24",
          "25",
          "26",
          "27",
          "28",
          "29",
          "30",
          "31",
          "32",
          "33",
          "34",
          "35",
          "36",
          "37",
          "38",
          "39",
          "40",
          "41",
          "42",
          "43",
          "44",
          "45",
          "46",
          "47",
          "48",
          "49",
          "50",
          "51",
          "52",
          "53",
          "54",
          "55",
          "56",
          "57",
          "58",
          "59",
          "60",
          "61",
          "62",
          "63",
          "64",
          "65",
          "66",
          "67",
          "68",
          "69",
          "70",
          "71",
          "72",
          "73",
          "74",
          "75",
          "76",
          "77",
          "78",
          "79",
          "80",
          "81",
          "82",
          "83",
          "84",
          "85",
          "86",
          "87",
          "88",
          "89",
          "90",
          "91",
          "92",
          "93",
          "94",
          "95",
          "96",
          "97",
          "98",
          "99",
          "100",
          "101",
          "102",
          "103",
          "104",
          "105",
          "106",
          "107",
          "108",
          "109",
          "110",
          "111",
          "112",
          "113",
          "114",
          "115",
          "116",
          "117",
          "118",
          "119",
          "120",
          "121",
          "122",
          "123",
          "124",
          "125",
          "126",
          "127",
          "128",
          "129",
          "130",
          "131",
          "132",
          "133",
          "134",
          "135",
          "136",
          "137",
          "138",
          "139",
          "140",
          "141",
          "142",
          "143",
          "144",
          "145",
          "146",
          "147",
          "148",
          "149",
          "150",
          "151",
          "152",
          "153",
          "154",
          "155",
          "156",
          "157",
          "158",
          "159",
          "160",
          "161",
          "162",
          "163",
          "164",
          "165",
          "166",
          "167",
          "168",
          "169",
          "170",
          "171",
          "172",
          "173",
          "174",
          "175",
          "176",
          "177",
          "178",
          "179",
          "180",
          "181",
          "182",
          "183",
          "184",
          "185",
          "186",
          "187",
          "188",
          "189",
          "190",
          "191",
          "192",
          "193",
          "194",
          "195",
          "196",
          "197",
          "198",
          "199",
          "200",
          "201",
          "202",
          "203",
          "204",
          "205",
          "206",
          "207",
          "208",
          "209",
          "210",
          "211",
          "212",
          "213",
          "214",
          "215",
          "216",
          "217",
          "218",
          "219",
          "220",
          "221",
          "222",
          "223",
          "224",
          "225",
          "226",
          "227",
          "228",
          "229",
          "230",
          "231",
          "232",
          "233",
          "234",
          "235",
          "236",
          "237",
          "238",
          "239",
          "240",
          "241",
          "242",
          "243",
          "244",
          "245",
          "246",
          "247",
          "248",
          "249",
          "250"
         ],
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250
         ],
         "xaxis": "x2",
         "y": [
          0.27305302023887634,
          0.25168633460998535,
          0.2805984914302826,
          0.23761962354183197,
          0.2510859966278076,
          0.27131256461143494,
          0.23749761283397675,
          0.24189652502536774,
          0.23628437519073486,
          0.25855696201324463,
          0.26950231194496155,
          0.23400017619132996,
          0.21096058189868927,
          0.21461766958236694,
          0.22335942089557648,
          0.26782649755477905,
          0.222210094332695,
          0.2088436782360077,
          0.21593618392944336,
          0.21657249331474304,
          0.21101169288158417,
          0.2328415811061859,
          0.2319042980670929,
          0.2171500325202942,
          0.21103841066360474,
          0.23880884051322937,
          0.20470476150512695,
          0.199915811419487,
          0.21566538512706757,
          0.20192308723926544,
          0.20941834151744843,
          0.19659468531608582,
          0.20027196407318115,
          0.19822458922863007,
          0.19532881677150726,
          0.1978542059659958,
          0.23568157851696014,
          0.17850738763809204,
          0.2161598652601242,
          0.20827855169773102,
          0.18101876974105835,
          0.2005397379398346,
          0.17871367931365967,
          0.18063314259052277,
          0.1958143711090088,
          0.1696271151304245,
          0.19007861614227295,
          0.19107091426849365,
          0.17440325021743774,
          0.18355832993984222,
          0.1827951967716217,
          0.22422316670417786,
          0.18787141144275665,
          0.17926490306854248,
          0.18554243445396423,
          0.19373154640197754,
          0.19628725945949554,
          0.18507356941699982,
          0.17645442485809326,
          0.1667463630437851,
          0.1649562269449234,
          0.18345296382904053,
          0.17509333789348602,
          0.18046291172504425,
          0.1722635179758072,
          0.19241087138652802,
          0.20972590148448944,
          0.16990886628627777,
          0.16930405795574188,
          0.1739267110824585,
          0.15526795387268066,
          0.17423683404922485,
          0.1718263030052185,
          0.18275757133960724,
          0.16612239181995392,
          0.1583072543144226,
          0.17638245224952698,
          0.1724092662334442,
          0.16934026777744293,
          0.17536813020706177,
          0.16784565150737762,
          0.1727818101644516,
          0.1652318686246872,
          0.15211449563503265,
          0.1824851632118225,
          0.19055557250976562,
          0.16881754994392395,
          0.15192899107933044,
          0.17410114407539368,
          0.16558071970939636,
          0.14930438995361328,
          0.15554703772068024,
          0.15800264477729797,
          0.16472822427749634,
          0.16796931624412537,
          0.1712244600057602,
          0.15367145836353302,
          0.16675858199596405,
          0.152052640914917,
          0.1478150337934494,
          0.1700132042169571,
          0.18722571432590485,
          0.16410453617572784,
          0.15179333090782166,
          0.17722809314727783,
          0.17590148746967316,
          0.15230780839920044,
          0.1512334942817688,
          0.15572330355644226,
          0.1503792405128479,
          0.1693076342344284,
          0.17486980557441711,
          0.14597323536872864,
          0.164179265499115,
          0.16113387048244476,
          0.14276345074176788,
          0.1525101661682129,
          0.16117902100086212,
          0.15427230298519135,
          0.14804694056510925,
          0.15362834930419922,
          0.15872982144355774,
          0.14207465946674347,
          0.1517900675535202,
          0.13938049972057343,
          0.14599044620990753,
          0.15782055258750916,
          0.14268679916858673,
          0.14039157330989838,
          0.14011135697364807,
          0.15628181397914886,
          0.16206368803977966,
          0.15487447381019592,
          0.16073064506053925,
          0.1385546177625656,
          0.139869824051857,
          0.15793144702911377,
          0.14329762756824493,
          0.14491583406925201,
          0.198842853307724,
          0.15109805762767792,
          0.15687955915927887,
          0.13967910408973694,
          0.14542658627033234,
          0.15430057048797607,
          0.15341730415821075,
          0.1547958105802536,
          0.12971650063991547,
          0.16245590150356293,
          0.13727077841758728,
          0.14890436828136444,
          0.14992691576480865,
          0.1414877325296402,
          0.16380426287651062,
          0.14225472509860992,
          0.13573934137821198,
          0.19886688888072968,
          0.13579198718070984,
          0.14798878133296967,
          0.13458630442619324,
          0.14626561105251312,
          0.14786718785762787,
          0.130202978849411,
          0.15637251734733582,
          0.13160787522792816,
          0.1807999461889267,
          0.15349681675434113,
          0.14806166291236877,
          0.12743572890758514,
          0.12622323632240295,
          0.20677758753299713,
          0.1426769644021988,
          0.15739169716835022,
          0.1462036818265915,
          0.12926112115383148,
          0.13287398219108582,
          0.1215900108218193,
          0.16573016345500946,
          0.14008311927318573,
          0.13760307431221008,
          0.1555599421262741,
          0.15687213838100433,
          0.14265458285808563,
          0.1346847116947174,
          0.1291121393442154,
          0.13584326207637787,
          0.1708042025566101,
          0.1462084949016571,
          0.14141614735126495,
          0.13895675539970398,
          0.13690464198589325,
          0.13104431331157684,
          0.14568719267845154,
          0.15943998098373413,
          0.14147105813026428,
          0.13055270910263062,
          0.15125128626823425,
          0.13160797953605652,
          0.14156202971935272,
          0.23098044097423553,
          0.14904382824897766,
          0.12765589356422424,
          0.1439914107322693,
          0.14058740437030792,
          0.13847237825393677,
          0.14238341152668,
          0.1311231106519699,
          0.14125223457813263,
          0.14886696636676788,
          0.1442035585641861,
          0.1527658998966217,
          0.1458641141653061,
          0.13401353359222412,
          0.14518862962722778,
          0.14213524758815765,
          0.13570435345172882,
          0.143046036362648,
          0.13419903814792633,
          0.13126978278160095,
          0.15048758685588837,
          0.1367778331041336,
          0.15006229281425476,
          0.12956438958644867,
          0.1448056995868683,
          0.13931572437286377,
          0.16950781643390656,
          0.14048178493976593,
          0.12371055036783218,
          0.12807953357696533,
          0.13277582824230194,
          0.14726664125919342,
          0.15474066138267517,
          0.135270357131958,
          0.11886337399482727,
          0.11878287047147751,
          0.13158364593982697,
          0.14044378697872162,
          0.12849655747413635,
          0.13301533460617065,
          0.1318296641111374,
          0.13874340057373047,
          0.13387680053710938,
          0.12559281289577484,
          0.14889992773532867,
          0.14372830092906952,
          0.13299182057380676,
          0.12681810557842255,
          0.14768283069133759,
          0.13407309353351593,
          0.1317579299211502
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "Magenta"
         },
         "mode": "markers+lines",
         "name": "Validation loss",
         "text": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12",
          "13",
          "14",
          "15",
          "16",
          "17",
          "18",
          "19",
          "20",
          "21",
          "22",
          "23",
          "24",
          "25",
          "26",
          "27",
          "28",
          "29",
          "30",
          "31",
          "32",
          "33",
          "34",
          "35",
          "36",
          "37",
          "38",
          "39",
          "40",
          "41",
          "42",
          "43",
          "44",
          "45",
          "46",
          "47",
          "48",
          "49",
          "50",
          "51",
          "52",
          "53",
          "54",
          "55",
          "56",
          "57",
          "58",
          "59",
          "60",
          "61",
          "62",
          "63",
          "64",
          "65",
          "66",
          "67",
          "68",
          "69",
          "70",
          "71",
          "72",
          "73",
          "74",
          "75",
          "76",
          "77",
          "78",
          "79",
          "80",
          "81",
          "82",
          "83",
          "84",
          "85",
          "86",
          "87",
          "88",
          "89",
          "90",
          "91",
          "92",
          "93",
          "94",
          "95",
          "96",
          "97",
          "98",
          "99",
          "100",
          "101",
          "102",
          "103",
          "104",
          "105",
          "106",
          "107",
          "108",
          "109",
          "110",
          "111",
          "112",
          "113",
          "114",
          "115",
          "116",
          "117",
          "118",
          "119",
          "120",
          "121",
          "122",
          "123",
          "124",
          "125",
          "126",
          "127",
          "128",
          "129",
          "130",
          "131",
          "132",
          "133",
          "134",
          "135",
          "136",
          "137",
          "138",
          "139",
          "140",
          "141",
          "142",
          "143",
          "144",
          "145",
          "146",
          "147",
          "148",
          "149",
          "150",
          "151",
          "152",
          "153",
          "154",
          "155",
          "156",
          "157",
          "158",
          "159",
          "160",
          "161",
          "162",
          "163",
          "164",
          "165",
          "166",
          "167",
          "168",
          "169",
          "170",
          "171",
          "172",
          "173",
          "174",
          "175",
          "176",
          "177",
          "178",
          "179",
          "180",
          "181",
          "182",
          "183",
          "184",
          "185",
          "186",
          "187",
          "188",
          "189",
          "190",
          "191",
          "192",
          "193",
          "194",
          "195",
          "196",
          "197",
          "198",
          "199",
          "200",
          "201",
          "202",
          "203",
          "204",
          "205",
          "206",
          "207",
          "208",
          "209",
          "210",
          "211",
          "212",
          "213",
          "214",
          "215",
          "216",
          "217",
          "218",
          "219",
          "220",
          "221",
          "222",
          "223",
          "224",
          "225",
          "226",
          "227",
          "228",
          "229",
          "230",
          "231",
          "232",
          "233",
          "234",
          "235",
          "236",
          "237",
          "238",
          "239",
          "240",
          "241",
          "242",
          "243",
          "244",
          "245",
          "246",
          "247",
          "248",
          "249",
          "250"
         ],
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250
         ],
         "xaxis": "x2",
         "y": [
          0.27553337812423706,
          0.27051734924316406,
          0.268149197101593,
          0.290406733751297,
          0.35725995898246765,
          0.36747193336486816,
          0.25711166858673096,
          0.21850408613681793,
          0.29268938302993774,
          0.29773131012916565,
          0.2553677260875702,
          0.25114789605140686,
          0.29148662090301514,
          0.3007223904132843,
          0.23228277266025543,
          0.3457050323486328,
          0.3228508532047272,
          0.29045039415359497,
          0.294609934091568,
          0.2587926983833313,
          0.32115328311920166,
          0.2591739892959595,
          0.3382081389427185,
          0.4141949713230133,
          0.3308083415031433,
          0.2818267047405243,
          0.2531445026397705,
          0.4765382409095764,
          0.26039063930511475,
          0.2813567519187927,
          0.26141923666000366,
          0.29439347982406616,
          0.31575584411621094,
          0.23306789994239807,
          0.23844270408153534,
          0.26373642683029175,
          0.2438240647315979,
          0.24299097061157227,
          0.2945014536380768,
          0.23085278272628784,
          0.2206490933895111,
          0.25686150789260864,
          0.2735242545604706,
          0.23987214267253876,
          0.2785889506340027,
          0.24790839850902557,
          0.21959301829338074,
          0.27871206402778625,
          0.2318638563156128,
          0.2948335111141205,
          0.3025328814983368,
          0.28328055143356323,
          0.2489725798368454,
          0.2842511832714081,
          0.24524696171283722,
          0.23096801340579987,
          0.2979412376880646,
          0.23908983170986176,
          0.23622296750545502,
          0.21270209550857544,
          0.2711157202720642,
          0.21105507016181946,
          0.2987144887447357,
          0.23282484710216522,
          0.24862731993198395,
          0.2283467799425125,
          0.256928414106369,
          0.25871434807777405,
          0.24163679778575897,
          0.19791993498802185,
          0.24964222311973572,
          0.2699632942676544,
          0.3143916726112366,
          0.22020019590854645,
          0.20332539081573486,
          0.2341935783624649,
          0.2456367164850235,
          0.24131977558135986,
          0.2287568300962448,
          0.23234394192695618,
          0.2397349774837494,
          0.24192926287651062,
          0.2202996015548706,
          0.1818305104970932,
          0.23619265854358673,
          0.2166878581047058,
          0.24050064384937286,
          0.23248043656349182,
          0.20443876087665558,
          0.2385842204093933,
          0.21166694164276123,
          0.18847526609897614,
          0.18306514620780945,
          0.2408532351255417,
          0.20267504453659058,
          0.2362193465232849,
          0.18526583909988403,
          0.2386370599269867,
          0.26705577969551086,
          0.22000905871391296,
          0.6387996077537537,
          0.24319681525230408,
          0.208618625998497,
          0.223852276802063,
          0.4380815029144287,
          0.30007970333099365,
          0.22146938741207123,
          0.24119935929775238,
          0.23332872986793518,
          0.20296305418014526,
          0.28369051218032837,
          0.22707587480545044,
          0.36472970247268677,
          0.22115086019039154,
          0.23575711250305176,
          0.21820199489593506,
          0.28713569045066833,
          0.18535926938056946,
          0.23304469883441925,
          0.2461279183626175,
          0.22211098670959473,
          0.2359119951725006,
          0.20801673829555511,
          0.19051523506641388,
          0.1955769807100296,
          0.249973863363266,
          0.221051886677742,
          0.1790127456188202,
          0.28004392981529236,
          0.24236607551574707,
          0.2288108617067337,
          0.22710178792476654,
          0.1978471726179123,
          0.19654828310012817,
          0.1918363869190216,
          0.2224481850862503,
          0.2167961597442627,
          0.25738415122032166,
          0.3319686949253082,
          0.397798091173172,
          0.1967511922121048,
          0.20694997906684875,
          0.2263767421245575,
          0.20022736489772797,
          0.22523270547389984,
          0.166826993227005,
          0.2245689183473587,
          0.2575426399707794,
          0.219182550907135,
          0.19917717576026917,
          0.21226809918880463,
          0.22318947315216064,
          0.21041704714298248,
          0.23111023008823395,
          0.2642412781715393,
          0.2877386212348938,
          0.26501980423927307,
          0.231151282787323,
          0.22092382609844208,
          0.1945260614156723,
          0.22810059785842896,
          0.19653668999671936,
          0.22986075282096863,
          0.27471211552619934,
          0.2782476544380188,
          0.198388010263443,
          0.2988237142562866,
          0.19753853976726532,
          0.2197103053331375,
          0.20655956864356995,
          0.272562712430954,
          0.2395017445087433,
          0.29695725440979004,
          0.22262683510780334,
          0.1894715130329132,
          0.25679895281791687,
          0.2090863734483719,
          0.26827025413513184,
          0.2117295265197754,
          0.23427455127239227,
          0.25180837512016296,
          0.24429871141910553,
          0.24747833609580994,
          0.250998854637146,
          0.2524554133415222,
          0.21259504556655884,
          0.22977399826049805,
          0.2968159317970276,
          0.26250025629997253,
          0.3010532855987549,
          0.2824000418186188,
          0.21055562794208527,
          0.2387346625328064,
          0.30960920453071594,
          0.23370032012462616,
          0.23616787791252136,
          0.2359435111284256,
          0.3557835817337036,
          0.2327648103237152,
          0.39015498757362366,
          0.24482755362987518,
          0.21017618477344513,
          0.256700336933136,
          0.23641853034496307,
          0.2323719561100006,
          0.26521167159080505,
          0.3001088500022888,
          0.2596690058708191,
          0.22063688933849335,
          0.3535671830177307,
          0.2842162847518921,
          0.2674405872821808,
          0.28003206849098206,
          0.28296858072280884,
          0.25953197479248047,
          0.30191805958747864,
          0.25015026330947876,
          0.2936987280845642,
          0.2799064815044403,
          0.2211121767759323,
          0.28974324464797974,
          0.2587941884994507,
          0.2666166126728058,
          0.27045491337776184,
          0.27322280406951904,
          0.2663830816745758,
          0.32918286323547363,
          0.23957902193069458,
          0.2688642740249634,
          0.18776579201221466,
          0.2571241855621338,
          0.2482341080904007,
          0.3037955164909363,
          0.26672783493995667,
          0.22192813456058502,
          0.32310983538627625,
          0.27470558881759644,
          0.2561807334423065,
          0.28871628642082214,
          0.27953407168388367,
          0.3510667085647583,
          0.2688440680503845,
          0.2771350145339966,
          0.31657272577285767,
          0.2811182737350464,
          0.24327687919139862,
          0.3427272140979767,
          0.3325706422328949,
          0.22931167483329773,
          0.3042820692062378
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Training and validation accuracy",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Training and validation loss",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "range": [
          0,
          1
         ],
         "title": {
          "text": "Accuracy"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ],
         "range": [
          0,
          1
         ],
         "title": {
          "text": "Loss"
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"8037ccc9-4d56-4671-b295-005c80d74749\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"8037ccc9-4d56-4671-b295-005c80d74749\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '8037ccc9-4d56-4671-b295-005c80d74749',\n",
       "                        [{\"marker\": {\"color\": \"Green\"}, \"mode\": \"markers+lines\", \"name\": \"Training accuracy\", \"text\": [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"30\", \"31\", \"32\", \"33\", \"34\", \"35\", \"36\", \"37\", \"38\", \"39\", \"40\", \"41\", \"42\", \"43\", \"44\", \"45\", \"46\", \"47\", \"48\", \"49\", \"50\", \"51\", \"52\", \"53\", \"54\", \"55\", \"56\", \"57\", \"58\", \"59\", \"60\", \"61\", \"62\", \"63\", \"64\", \"65\", \"66\", \"67\", \"68\", \"69\", \"70\", \"71\", \"72\", \"73\", \"74\", \"75\", \"76\", \"77\", \"78\", \"79\", \"80\", \"81\", \"82\", \"83\", \"84\", \"85\", \"86\", \"87\", \"88\", \"89\", \"90\", \"91\", \"92\", \"93\", \"94\", \"95\", \"96\", \"97\", \"98\", \"99\", \"100\", \"101\", \"102\", \"103\", \"104\", \"105\", \"106\", \"107\", \"108\", \"109\", \"110\", \"111\", \"112\", \"113\", \"114\", \"115\", \"116\", \"117\", \"118\", \"119\", \"120\", \"121\", \"122\", \"123\", \"124\", \"125\", \"126\", \"127\", \"128\", \"129\", \"130\", \"131\", \"132\", \"133\", \"134\", \"135\", \"136\", \"137\", \"138\", \"139\", \"140\", \"141\", \"142\", \"143\", \"144\", \"145\", \"146\", \"147\", \"148\", \"149\", \"150\", \"151\", \"152\", \"153\", \"154\", \"155\", \"156\", \"157\", \"158\", \"159\", \"160\", \"161\", \"162\", \"163\", \"164\", \"165\", \"166\", \"167\", \"168\", \"169\", \"170\", \"171\", \"172\", \"173\", \"174\", \"175\", \"176\", \"177\", \"178\", \"179\", \"180\", \"181\", \"182\", \"183\", \"184\", \"185\", \"186\", \"187\", \"188\", \"189\", \"190\", \"191\", \"192\", \"193\", \"194\", \"195\", \"196\", \"197\", \"198\", \"199\", \"200\", \"201\", \"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\", \"211\", \"212\", \"213\", \"214\", \"215\", \"216\", \"217\", \"218\", \"219\", \"220\", \"221\", \"222\", \"223\", \"224\", \"225\", \"226\", \"227\", \"228\", \"229\", \"230\", \"231\", \"232\", \"233\", \"234\", \"235\", \"236\", \"237\", \"238\", \"239\", \"240\", \"241\", \"242\", \"243\", \"244\", \"245\", \"246\", \"247\", \"248\", \"249\", \"250\"], \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250], \"xaxis\": \"x\", \"y\": [0.884255051612854, 0.8933212161064148, 0.8766999244689941, 0.8945300579071045, 0.8851616978645325, 0.8812329769134521, 0.895436704158783, 0.895436704158783, 0.9005742073059082, 0.8863704800605774, 0.8824418187141418, 0.8921124339103699, 0.9099425673484802, 0.899969756603241, 0.9008764028549194, 0.8881837129592896, 0.9029918313026428, 0.9072227478027344, 0.8990631699562073, 0.9066182971000671, 0.9069204926490784, 0.9008764028549194, 0.9023874402046204, 0.9075249433517456, 0.9045028686523438, 0.8981565237045288, 0.909640371799469, 0.9132668375968933, 0.9117558002471924, 0.9138712882995605, 0.9054095149040222, 0.9150800704956055, 0.9102447628974915, 0.9105470180511475, 0.9108492136001587, 0.9147778749465942, 0.8969477415084839, 0.9190087914466858, 0.9069204926490784, 0.9023874402046204, 0.9226352572441101, 0.9156845211982727, 0.9214264154434204, 0.9226352572441101, 0.9129646420478821, 0.9247506856918335, 0.9126624464988708, 0.9220308065414429, 0.9229374527931213, 0.9211242198944092, 0.9199153780937195, 0.9093381762504578, 0.9184043407440186, 0.9214264154434204, 0.9205197691917419, 0.9168933033943176, 0.9153822660446167, 0.9247506856918335, 0.9268661141395569, 0.9268661141395569, 0.9310970306396484, 0.9190087914466858, 0.9274705052375793, 0.9196131825447083, 0.9247506856918335, 0.9196131825447083, 0.9132668375968933, 0.93019038438797, 0.9220308065414429, 0.9205197691917419, 0.9295859932899475, 0.9259595274925232, 0.9235418438911438, 0.9187065362930298, 0.9292837977409363, 0.9244484901428223, 0.9177999496459961, 0.9307947754859924, 0.928679347038269, 0.9232396483421326, 0.9223330020904541, 0.9268661141395569, 0.9262617230415344, 0.9326080679893494, 0.9256572723388672, 0.9199153780937195, 0.924146294593811, 0.9262617230415344, 0.9244484901428223, 0.9338168501853943, 0.9344213008880615, 0.9277727603912354, 0.9332124590873718, 0.928679347038269, 0.9244484901428223, 0.9199153780937195, 0.9317014217376709, 0.9310970306396484, 0.9326080679893494, 0.9374433159828186, 0.9317014217376709, 0.9298881888389587, 0.9274705052375793, 0.9329102635383606, 0.9277727603912354, 0.9274705052375793, 0.9353278875350952, 0.9338168501853943, 0.9298881888389587, 0.9307947754859924, 0.9310970306396484, 0.9220308065414429, 0.9365367293357849, 0.9304925799369812, 0.9320036172866821, 0.9383499622344971, 0.935025691986084, 0.9292837977409363, 0.9362345337867737, 0.9386521577835083, 0.9323058128356934, 0.9341190457344055, 0.9347234964370728, 0.9371411204338074, 0.9365367293357849, 0.9341190457344055, 0.9313992261886597, 0.9356300830841064, 0.9407675862312317, 0.9374433159828186, 0.935025691986084, 0.9317014217376709, 0.9380477666854858, 0.9289815425872803, 0.9362345337867737, 0.9419764280319214, 0.9386521577835083, 0.9338168501853943, 0.9329102635383606, 0.9205197691917419, 0.9359322786331177, 0.9323058128356934, 0.9380477666854858, 0.9365367293357849, 0.9359322786331177, 0.9335146546363831, 0.9347234964370728, 0.939860999584198, 0.9313992261886597, 0.9392565488815308, 0.9347234964370728, 0.9359322786331177, 0.9371411204338074, 0.9277727603912354, 0.9404653906822205, 0.9383499622344971, 0.9184043407440186, 0.9440918564796448, 0.9329102635383606, 0.9380477666854858, 0.9377455711364746, 0.9344213008880615, 0.9431852698326111, 0.9392565488815308, 0.9413720369338989, 0.9271683096885681, 0.9368389248847961, 0.9365367293357849, 0.9434874653816223, 0.9431852698326111, 0.9250528812408447, 0.9425808191299438, 0.9274705052375793, 0.9410697817802429, 0.9449985027313232, 0.9437896609306335, 0.9483227729797363, 0.9326080679893494, 0.9389543533325195, 0.939860999584198, 0.9356300830841064, 0.9359322786331177, 0.9386521577835083, 0.9422786235809326, 0.9410697817802429, 0.9392565488815308, 0.9304925799369812, 0.9371411204338074, 0.9374433159828186, 0.9419764280319214, 0.9419764280319214, 0.9453006982803345, 0.9344213008880615, 0.935025691986084, 0.9380477666854858, 0.9459050893783569, 0.9407675862312317, 0.9413720369338989, 0.9389543533325195, 0.9120579957962036, 0.9377455711364746, 0.944696307182312, 0.9386521577835083, 0.9407675862312317, 0.9389543533325195, 0.9371411204338074, 0.9410697817802429, 0.9407675862312317, 0.9380477666854858, 0.9407675862312317, 0.9353278875350952, 0.9368389248847961, 0.939860999584198, 0.9317014217376709, 0.9407675862312317, 0.9416742324829102, 0.939860999584198, 0.9392565488815308, 0.9389543533325195, 0.9362345337867737, 0.9422786235809326, 0.9383499622344971, 0.9440918564796448, 0.9410697817802429, 0.9383499622344971, 0.9307947754859924, 0.9389543533325195, 0.9465095400810242, 0.9462072849273682, 0.9416742324829102, 0.9371411204338074, 0.9386521577835083, 0.9389543533325195, 0.9416742324829102, 0.9456028938293457, 0.9434874653816223, 0.9392565488815308, 0.9413720369338989, 0.9389543533325195, 0.9465095400810242, 0.939860999584198, 0.9374433159828186, 0.9440918564796448, 0.939860999584198, 0.9377455711364746, 0.9389543533325195, 0.9419764280319214, 0.9353278875350952, 0.9386521577835083, 0.9428830742835999], \"yaxis\": \"y\"}, {\"marker\": {\"color\": \"Red\"}, \"mode\": \"markers+lines\", \"name\": \"Validation accuracy\", \"text\": [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"30\", \"31\", \"32\", \"33\", \"34\", \"35\", \"36\", \"37\", \"38\", \"39\", \"40\", \"41\", \"42\", \"43\", \"44\", \"45\", \"46\", \"47\", \"48\", \"49\", \"50\", \"51\", \"52\", \"53\", \"54\", \"55\", \"56\", \"57\", \"58\", \"59\", \"60\", \"61\", \"62\", \"63\", \"64\", \"65\", \"66\", \"67\", \"68\", \"69\", \"70\", \"71\", \"72\", \"73\", \"74\", \"75\", \"76\", \"77\", \"78\", \"79\", \"80\", \"81\", \"82\", \"83\", \"84\", \"85\", \"86\", \"87\", \"88\", \"89\", \"90\", \"91\", \"92\", \"93\", \"94\", \"95\", \"96\", \"97\", \"98\", \"99\", \"100\", \"101\", \"102\", \"103\", \"104\", \"105\", \"106\", \"107\", \"108\", \"109\", \"110\", \"111\", \"112\", \"113\", \"114\", \"115\", \"116\", \"117\", \"118\", \"119\", \"120\", \"121\", \"122\", \"123\", \"124\", \"125\", \"126\", \"127\", \"128\", \"129\", \"130\", \"131\", \"132\", \"133\", \"134\", \"135\", \"136\", \"137\", \"138\", \"139\", \"140\", \"141\", \"142\", \"143\", \"144\", \"145\", \"146\", \"147\", \"148\", \"149\", \"150\", \"151\", \"152\", \"153\", \"154\", \"155\", \"156\", \"157\", \"158\", \"159\", \"160\", \"161\", \"162\", \"163\", \"164\", \"165\", \"166\", \"167\", \"168\", \"169\", \"170\", \"171\", \"172\", \"173\", \"174\", \"175\", \"176\", \"177\", \"178\", \"179\", \"180\", \"181\", \"182\", \"183\", \"184\", \"185\", \"186\", \"187\", \"188\", \"189\", \"190\", \"191\", \"192\", \"193\", \"194\", \"195\", \"196\", \"197\", \"198\", \"199\", \"200\", \"201\", \"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\", \"211\", \"212\", \"213\", \"214\", \"215\", \"216\", \"217\", \"218\", \"219\", \"220\", \"221\", \"222\", \"223\", \"224\", \"225\", \"226\", \"227\", \"228\", \"229\", \"230\", \"231\", \"232\", \"233\", \"234\", \"235\", \"236\", \"237\", \"238\", \"239\", \"240\", \"241\", \"242\", \"243\", \"244\", \"245\", \"246\", \"247\", \"248\", \"249\", \"250\"], \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250], \"xaxis\": \"x\", \"y\": [0.8852657079696655, 0.8780193328857422, 0.8961352705955505, 0.8792270421981812, 0.8599033951759338, 0.8369565010070801, 0.8925120830535889, 0.9094203114509583, 0.8756038546562195, 0.8888888955116272, 0.9033816456794739, 0.9033816456794739, 0.8756038546562195, 0.8695651888847351, 0.8997584581375122, 0.8550724387168884, 0.8719806671142578, 0.8888888955116272, 0.8756038546562195, 0.8949275612831116, 0.8816425204277039, 0.8840579986572266, 0.8574879169464111, 0.8490338325500488, 0.8671497702598572, 0.8768116235733032, 0.8985507488250732, 0.8285024166107178, 0.8949275612831116, 0.8961352705955505, 0.8876811861991882, 0.8780193328857422, 0.8768116235733032, 0.9045893549919128, 0.9009661674499512, 0.8864734172821045, 0.8985507488250732, 0.9021739363670349, 0.8888888955116272, 0.9082125425338745, 0.9142512083053589, 0.9021739363670349, 0.8913043737411499, 0.9106280207633972, 0.8913043737411499, 0.9021739363670349, 0.9154589176177979, 0.8900966048240662, 0.9057971239089966, 0.8840579986572266, 0.8900966048240662, 0.8852657079696655, 0.9045893549919128, 0.8804348111152649, 0.9057971239089966, 0.9070048332214355, 0.8719806671142578, 0.9021739363670349, 0.9166666865348816, 0.9106280207633972, 0.8925120830535889, 0.9202898740768433, 0.8768116235733032, 0.9178743958473206, 0.9070048332214355, 0.9106280207633972, 0.8985507488250732, 0.8937197923660278, 0.9130434989929199, 0.9154589176177979, 0.9094203114509583, 0.9021739363670349, 0.8840579986572266, 0.9142512083053589, 0.9239130616188049, 0.9118357300758362, 0.9033816456794739, 0.9070048332214355, 0.9202898740768433, 0.9178743958473206, 0.8985507488250732, 0.9009661674499512, 0.9142512083053589, 0.9396135210990906, 0.9190821051597595, 0.9214975833892822, 0.9057971239089966, 0.9154589176177979, 0.9251207709312439, 0.9094203114509583, 0.9166666865348816, 0.9371980428695679, 0.9227052927017212, 0.9033816456794739, 0.9227052927017212, 0.9094203114509583, 0.9311594367027283, 0.9154589176177979, 0.8973429799079895, 0.9142512083053589, 0.8007246255874634, 0.9082125425338745, 0.9154589176177979, 0.9227052927017212, 0.8719806671142578, 0.8876811861991882, 0.9190821051597595, 0.9142512083053589, 0.9094203114509583, 0.9251207709312439, 0.9045893549919128, 0.9166666865348816, 0.8599033951759338, 0.9239130616188049, 0.9142512083053589, 0.9202898740768433, 0.8949275612831116, 0.9323671460151672, 0.9118357300758362, 0.9057971239089966, 0.9287439584732056, 0.9154589176177979, 0.9202898740768433, 0.9251207709312439, 0.9287439584732056, 0.9045893549919128, 0.9130434989929199, 0.9359903335571289, 0.8900966048240662, 0.9045893549919128, 0.9227052927017212, 0.9214975833892822, 0.9287439584732056, 0.9335748553276062, 0.9311594367027283, 0.9227052927017212, 0.9118357300758362, 0.9094203114509583, 0.8731883764266968, 0.8526570200920105, 0.9299516677856445, 0.9323671460151672, 0.9166666865348816, 0.9263284802436829, 0.9239130616188049, 0.9396135210990906, 0.9178743958473206, 0.9009661674499512, 0.9275362491607666, 0.9227052927017212, 0.9239130616188049, 0.9214975833892822, 0.9227052927017212, 0.9214975833892822, 0.8973429799079895, 0.8900966048240662, 0.9057971239089966, 0.9166666865348816, 0.9142512083053589, 0.9359903335571289, 0.9178743958473206, 0.9287439584732056, 0.9057971239089966, 0.8949275612831116, 0.9094203114509583, 0.9263284802436829, 0.8780193328857422, 0.9287439584732056, 0.9166666865348816, 0.9263284802436829, 0.8973429799079895, 0.9202898740768433, 0.9166666865348816, 0.9202898740768433, 0.9263284802436829, 0.8973429799079895, 0.9263284802436829, 0.9021739363670349, 0.9190821051597595, 0.9154589176177979, 0.9057971239089966, 0.9021739363670349, 0.9166666865348816, 0.9057971239089966, 0.9009661674499512, 0.9202898740768433, 0.9106280207633972, 0.8973429799079895, 0.9082125425338745, 0.9045893549919128, 0.9057971239089966, 0.9154589176177979, 0.9021739363670349, 0.8840579986572266, 0.9118357300758362, 0.9130434989929199, 0.9154589176177979, 0.8538647294044495, 0.9202898740768433, 0.8574879169464111, 0.8973429799079895, 0.9202898740768433, 0.9033816456794739, 0.9130434989929199, 0.9142512083053589, 0.9021739363670349, 0.8961352705955505, 0.9094203114509583, 0.9142512083053589, 0.8852657079696655, 0.8973429799079895, 0.8985507488250732, 0.8949275612831116, 0.8973429799079895, 0.8997584581375122, 0.8864734172821045, 0.9021739363670349, 0.8900966048240662, 0.8828502297401428, 0.9154589176177979, 0.8925120830535889, 0.8973429799079895, 0.8997584581375122, 0.8925120830535889, 0.9045893549919128, 0.9070048332214355, 0.8659420013427734, 0.9106280207633972, 0.9009661674499512, 0.9287439584732056, 0.9130434989929199, 0.9118357300758362, 0.8973429799079895, 0.9045893549919128, 0.9202898740768433, 0.8925120830535889, 0.9021739363670349, 0.9094203114509583, 0.8985507488250732, 0.9033816456794739, 0.8828502297401428, 0.9009661674499512, 0.8876811861991882, 0.9045893549919128, 0.8985507488250732, 0.9082125425338745, 0.8864734172821045, 0.8792270421981812, 0.9166666865348816, 0.9070048332214355], \"yaxis\": \"y\"}, {\"marker\": {\"color\": \"Blue\"}, \"mode\": \"markers+lines\", \"name\": \"Training loss\", \"text\": [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"30\", \"31\", \"32\", \"33\", \"34\", \"35\", \"36\", \"37\", \"38\", \"39\", \"40\", \"41\", \"42\", \"43\", \"44\", \"45\", \"46\", \"47\", \"48\", \"49\", \"50\", \"51\", \"52\", \"53\", \"54\", \"55\", \"56\", \"57\", \"58\", \"59\", \"60\", \"61\", \"62\", \"63\", \"64\", \"65\", \"66\", \"67\", \"68\", \"69\", \"70\", \"71\", \"72\", \"73\", \"74\", \"75\", \"76\", \"77\", \"78\", \"79\", \"80\", \"81\", \"82\", \"83\", \"84\", \"85\", \"86\", \"87\", \"88\", \"89\", \"90\", \"91\", \"92\", \"93\", \"94\", \"95\", \"96\", \"97\", \"98\", \"99\", \"100\", \"101\", \"102\", \"103\", \"104\", \"105\", \"106\", \"107\", \"108\", \"109\", \"110\", \"111\", \"112\", \"113\", \"114\", \"115\", \"116\", \"117\", \"118\", \"119\", \"120\", \"121\", \"122\", \"123\", \"124\", \"125\", \"126\", \"127\", \"128\", \"129\", \"130\", \"131\", \"132\", \"133\", \"134\", \"135\", \"136\", \"137\", \"138\", \"139\", \"140\", \"141\", \"142\", \"143\", \"144\", \"145\", \"146\", \"147\", \"148\", \"149\", \"150\", \"151\", \"152\", \"153\", \"154\", \"155\", \"156\", \"157\", \"158\", \"159\", \"160\", \"161\", \"162\", \"163\", \"164\", \"165\", \"166\", \"167\", \"168\", \"169\", \"170\", \"171\", \"172\", \"173\", \"174\", \"175\", \"176\", \"177\", \"178\", \"179\", \"180\", \"181\", \"182\", \"183\", \"184\", \"185\", \"186\", \"187\", \"188\", \"189\", \"190\", \"191\", \"192\", \"193\", \"194\", \"195\", \"196\", \"197\", \"198\", \"199\", \"200\", \"201\", \"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\", \"211\", \"212\", \"213\", \"214\", \"215\", \"216\", \"217\", \"218\", \"219\", \"220\", \"221\", \"222\", \"223\", \"224\", \"225\", \"226\", \"227\", \"228\", \"229\", \"230\", \"231\", \"232\", \"233\", \"234\", \"235\", \"236\", \"237\", \"238\", \"239\", \"240\", \"241\", \"242\", \"243\", \"244\", \"245\", \"246\", \"247\", \"248\", \"249\", \"250\"], \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250], \"xaxis\": \"x2\", \"y\": [0.27305302023887634, 0.25168633460998535, 0.2805984914302826, 0.23761962354183197, 0.2510859966278076, 0.27131256461143494, 0.23749761283397675, 0.24189652502536774, 0.23628437519073486, 0.25855696201324463, 0.26950231194496155, 0.23400017619132996, 0.21096058189868927, 0.21461766958236694, 0.22335942089557648, 0.26782649755477905, 0.222210094332695, 0.2088436782360077, 0.21593618392944336, 0.21657249331474304, 0.21101169288158417, 0.2328415811061859, 0.2319042980670929, 0.2171500325202942, 0.21103841066360474, 0.23880884051322937, 0.20470476150512695, 0.199915811419487, 0.21566538512706757, 0.20192308723926544, 0.20941834151744843, 0.19659468531608582, 0.20027196407318115, 0.19822458922863007, 0.19532881677150726, 0.1978542059659958, 0.23568157851696014, 0.17850738763809204, 0.2161598652601242, 0.20827855169773102, 0.18101876974105835, 0.2005397379398346, 0.17871367931365967, 0.18063314259052277, 0.1958143711090088, 0.1696271151304245, 0.19007861614227295, 0.19107091426849365, 0.17440325021743774, 0.18355832993984222, 0.1827951967716217, 0.22422316670417786, 0.18787141144275665, 0.17926490306854248, 0.18554243445396423, 0.19373154640197754, 0.19628725945949554, 0.18507356941699982, 0.17645442485809326, 0.1667463630437851, 0.1649562269449234, 0.18345296382904053, 0.17509333789348602, 0.18046291172504425, 0.1722635179758072, 0.19241087138652802, 0.20972590148448944, 0.16990886628627777, 0.16930405795574188, 0.1739267110824585, 0.15526795387268066, 0.17423683404922485, 0.1718263030052185, 0.18275757133960724, 0.16612239181995392, 0.1583072543144226, 0.17638245224952698, 0.1724092662334442, 0.16934026777744293, 0.17536813020706177, 0.16784565150737762, 0.1727818101644516, 0.1652318686246872, 0.15211449563503265, 0.1824851632118225, 0.19055557250976562, 0.16881754994392395, 0.15192899107933044, 0.17410114407539368, 0.16558071970939636, 0.14930438995361328, 0.15554703772068024, 0.15800264477729797, 0.16472822427749634, 0.16796931624412537, 0.1712244600057602, 0.15367145836353302, 0.16675858199596405, 0.152052640914917, 0.1478150337934494, 0.1700132042169571, 0.18722571432590485, 0.16410453617572784, 0.15179333090782166, 0.17722809314727783, 0.17590148746967316, 0.15230780839920044, 0.1512334942817688, 0.15572330355644226, 0.1503792405128479, 0.1693076342344284, 0.17486980557441711, 0.14597323536872864, 0.164179265499115, 0.16113387048244476, 0.14276345074176788, 0.1525101661682129, 0.16117902100086212, 0.15427230298519135, 0.14804694056510925, 0.15362834930419922, 0.15872982144355774, 0.14207465946674347, 0.1517900675535202, 0.13938049972057343, 0.14599044620990753, 0.15782055258750916, 0.14268679916858673, 0.14039157330989838, 0.14011135697364807, 0.15628181397914886, 0.16206368803977966, 0.15487447381019592, 0.16073064506053925, 0.1385546177625656, 0.139869824051857, 0.15793144702911377, 0.14329762756824493, 0.14491583406925201, 0.198842853307724, 0.15109805762767792, 0.15687955915927887, 0.13967910408973694, 0.14542658627033234, 0.15430057048797607, 0.15341730415821075, 0.1547958105802536, 0.12971650063991547, 0.16245590150356293, 0.13727077841758728, 0.14890436828136444, 0.14992691576480865, 0.1414877325296402, 0.16380426287651062, 0.14225472509860992, 0.13573934137821198, 0.19886688888072968, 0.13579198718070984, 0.14798878133296967, 0.13458630442619324, 0.14626561105251312, 0.14786718785762787, 0.130202978849411, 0.15637251734733582, 0.13160787522792816, 0.1807999461889267, 0.15349681675434113, 0.14806166291236877, 0.12743572890758514, 0.12622323632240295, 0.20677758753299713, 0.1426769644021988, 0.15739169716835022, 0.1462036818265915, 0.12926112115383148, 0.13287398219108582, 0.1215900108218193, 0.16573016345500946, 0.14008311927318573, 0.13760307431221008, 0.1555599421262741, 0.15687213838100433, 0.14265458285808563, 0.1346847116947174, 0.1291121393442154, 0.13584326207637787, 0.1708042025566101, 0.1462084949016571, 0.14141614735126495, 0.13895675539970398, 0.13690464198589325, 0.13104431331157684, 0.14568719267845154, 0.15943998098373413, 0.14147105813026428, 0.13055270910263062, 0.15125128626823425, 0.13160797953605652, 0.14156202971935272, 0.23098044097423553, 0.14904382824897766, 0.12765589356422424, 0.1439914107322693, 0.14058740437030792, 0.13847237825393677, 0.14238341152668, 0.1311231106519699, 0.14125223457813263, 0.14886696636676788, 0.1442035585641861, 0.1527658998966217, 0.1458641141653061, 0.13401353359222412, 0.14518862962722778, 0.14213524758815765, 0.13570435345172882, 0.143046036362648, 0.13419903814792633, 0.13126978278160095, 0.15048758685588837, 0.1367778331041336, 0.15006229281425476, 0.12956438958644867, 0.1448056995868683, 0.13931572437286377, 0.16950781643390656, 0.14048178493976593, 0.12371055036783218, 0.12807953357696533, 0.13277582824230194, 0.14726664125919342, 0.15474066138267517, 0.135270357131958, 0.11886337399482727, 0.11878287047147751, 0.13158364593982697, 0.14044378697872162, 0.12849655747413635, 0.13301533460617065, 0.1318296641111374, 0.13874340057373047, 0.13387680053710938, 0.12559281289577484, 0.14889992773532867, 0.14372830092906952, 0.13299182057380676, 0.12681810557842255, 0.14768283069133759, 0.13407309353351593, 0.1317579299211502], \"yaxis\": \"y2\"}, {\"marker\": {\"color\": \"Magenta\"}, \"mode\": \"markers+lines\", \"name\": \"Validation loss\", \"text\": [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"30\", \"31\", \"32\", \"33\", \"34\", \"35\", \"36\", \"37\", \"38\", \"39\", \"40\", \"41\", \"42\", \"43\", \"44\", \"45\", \"46\", \"47\", \"48\", \"49\", \"50\", \"51\", \"52\", \"53\", \"54\", \"55\", \"56\", \"57\", \"58\", \"59\", \"60\", \"61\", \"62\", \"63\", \"64\", \"65\", \"66\", \"67\", \"68\", \"69\", \"70\", \"71\", \"72\", \"73\", \"74\", \"75\", \"76\", \"77\", \"78\", \"79\", \"80\", \"81\", \"82\", \"83\", \"84\", \"85\", \"86\", \"87\", \"88\", \"89\", \"90\", \"91\", \"92\", \"93\", \"94\", \"95\", \"96\", \"97\", \"98\", \"99\", \"100\", \"101\", \"102\", \"103\", \"104\", \"105\", \"106\", \"107\", \"108\", \"109\", \"110\", \"111\", \"112\", \"113\", \"114\", \"115\", \"116\", \"117\", \"118\", \"119\", \"120\", \"121\", \"122\", \"123\", \"124\", \"125\", \"126\", \"127\", \"128\", \"129\", \"130\", \"131\", \"132\", \"133\", \"134\", \"135\", \"136\", \"137\", \"138\", \"139\", \"140\", \"141\", \"142\", \"143\", \"144\", \"145\", \"146\", \"147\", \"148\", \"149\", \"150\", \"151\", \"152\", \"153\", \"154\", \"155\", \"156\", \"157\", \"158\", \"159\", \"160\", \"161\", \"162\", \"163\", \"164\", \"165\", \"166\", \"167\", \"168\", \"169\", \"170\", \"171\", \"172\", \"173\", \"174\", \"175\", \"176\", \"177\", \"178\", \"179\", \"180\", \"181\", \"182\", \"183\", \"184\", \"185\", \"186\", \"187\", \"188\", \"189\", \"190\", \"191\", \"192\", \"193\", \"194\", \"195\", \"196\", \"197\", \"198\", \"199\", \"200\", \"201\", \"202\", \"203\", \"204\", \"205\", \"206\", \"207\", \"208\", \"209\", \"210\", \"211\", \"212\", \"213\", \"214\", \"215\", \"216\", \"217\", \"218\", \"219\", \"220\", \"221\", \"222\", \"223\", \"224\", \"225\", \"226\", \"227\", \"228\", \"229\", \"230\", \"231\", \"232\", \"233\", \"234\", \"235\", \"236\", \"237\", \"238\", \"239\", \"240\", \"241\", \"242\", \"243\", \"244\", \"245\", \"246\", \"247\", \"248\", \"249\", \"250\"], \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250], \"xaxis\": \"x2\", \"y\": [0.27553337812423706, 0.27051734924316406, 0.268149197101593, 0.290406733751297, 0.35725995898246765, 0.36747193336486816, 0.25711166858673096, 0.21850408613681793, 0.29268938302993774, 0.29773131012916565, 0.2553677260875702, 0.25114789605140686, 0.29148662090301514, 0.3007223904132843, 0.23228277266025543, 0.3457050323486328, 0.3228508532047272, 0.29045039415359497, 0.294609934091568, 0.2587926983833313, 0.32115328311920166, 0.2591739892959595, 0.3382081389427185, 0.4141949713230133, 0.3308083415031433, 0.2818267047405243, 0.2531445026397705, 0.4765382409095764, 0.26039063930511475, 0.2813567519187927, 0.26141923666000366, 0.29439347982406616, 0.31575584411621094, 0.23306789994239807, 0.23844270408153534, 0.26373642683029175, 0.2438240647315979, 0.24299097061157227, 0.2945014536380768, 0.23085278272628784, 0.2206490933895111, 0.25686150789260864, 0.2735242545604706, 0.23987214267253876, 0.2785889506340027, 0.24790839850902557, 0.21959301829338074, 0.27871206402778625, 0.2318638563156128, 0.2948335111141205, 0.3025328814983368, 0.28328055143356323, 0.2489725798368454, 0.2842511832714081, 0.24524696171283722, 0.23096801340579987, 0.2979412376880646, 0.23908983170986176, 0.23622296750545502, 0.21270209550857544, 0.2711157202720642, 0.21105507016181946, 0.2987144887447357, 0.23282484710216522, 0.24862731993198395, 0.2283467799425125, 0.256928414106369, 0.25871434807777405, 0.24163679778575897, 0.19791993498802185, 0.24964222311973572, 0.2699632942676544, 0.3143916726112366, 0.22020019590854645, 0.20332539081573486, 0.2341935783624649, 0.2456367164850235, 0.24131977558135986, 0.2287568300962448, 0.23234394192695618, 0.2397349774837494, 0.24192926287651062, 0.2202996015548706, 0.1818305104970932, 0.23619265854358673, 0.2166878581047058, 0.24050064384937286, 0.23248043656349182, 0.20443876087665558, 0.2385842204093933, 0.21166694164276123, 0.18847526609897614, 0.18306514620780945, 0.2408532351255417, 0.20267504453659058, 0.2362193465232849, 0.18526583909988403, 0.2386370599269867, 0.26705577969551086, 0.22000905871391296, 0.6387996077537537, 0.24319681525230408, 0.208618625998497, 0.223852276802063, 0.4380815029144287, 0.30007970333099365, 0.22146938741207123, 0.24119935929775238, 0.23332872986793518, 0.20296305418014526, 0.28369051218032837, 0.22707587480545044, 0.36472970247268677, 0.22115086019039154, 0.23575711250305176, 0.21820199489593506, 0.28713569045066833, 0.18535926938056946, 0.23304469883441925, 0.2461279183626175, 0.22211098670959473, 0.2359119951725006, 0.20801673829555511, 0.19051523506641388, 0.1955769807100296, 0.249973863363266, 0.221051886677742, 0.1790127456188202, 0.28004392981529236, 0.24236607551574707, 0.2288108617067337, 0.22710178792476654, 0.1978471726179123, 0.19654828310012817, 0.1918363869190216, 0.2224481850862503, 0.2167961597442627, 0.25738415122032166, 0.3319686949253082, 0.397798091173172, 0.1967511922121048, 0.20694997906684875, 0.2263767421245575, 0.20022736489772797, 0.22523270547389984, 0.166826993227005, 0.2245689183473587, 0.2575426399707794, 0.219182550907135, 0.19917717576026917, 0.21226809918880463, 0.22318947315216064, 0.21041704714298248, 0.23111023008823395, 0.2642412781715393, 0.2877386212348938, 0.26501980423927307, 0.231151282787323, 0.22092382609844208, 0.1945260614156723, 0.22810059785842896, 0.19653668999671936, 0.22986075282096863, 0.27471211552619934, 0.2782476544380188, 0.198388010263443, 0.2988237142562866, 0.19753853976726532, 0.2197103053331375, 0.20655956864356995, 0.272562712430954, 0.2395017445087433, 0.29695725440979004, 0.22262683510780334, 0.1894715130329132, 0.25679895281791687, 0.2090863734483719, 0.26827025413513184, 0.2117295265197754, 0.23427455127239227, 0.25180837512016296, 0.24429871141910553, 0.24747833609580994, 0.250998854637146, 0.2524554133415222, 0.21259504556655884, 0.22977399826049805, 0.2968159317970276, 0.26250025629997253, 0.3010532855987549, 0.2824000418186188, 0.21055562794208527, 0.2387346625328064, 0.30960920453071594, 0.23370032012462616, 0.23616787791252136, 0.2359435111284256, 0.3557835817337036, 0.2327648103237152, 0.39015498757362366, 0.24482755362987518, 0.21017618477344513, 0.256700336933136, 0.23641853034496307, 0.2323719561100006, 0.26521167159080505, 0.3001088500022888, 0.2596690058708191, 0.22063688933849335, 0.3535671830177307, 0.2842162847518921, 0.2674405872821808, 0.28003206849098206, 0.28296858072280884, 0.25953197479248047, 0.30191805958747864, 0.25015026330947876, 0.2936987280845642, 0.2799064815044403, 0.2211121767759323, 0.28974324464797974, 0.2587941884994507, 0.2666166126728058, 0.27045491337776184, 0.27322280406951904, 0.2663830816745758, 0.32918286323547363, 0.23957902193069458, 0.2688642740249634, 0.18776579201221466, 0.2571241855621338, 0.2482341080904007, 0.3037955164909363, 0.26672783493995667, 0.22192813456058502, 0.32310983538627625, 0.27470558881759644, 0.2561807334423065, 0.28871628642082214, 0.27953407168388367, 0.3510667085647583, 0.2688440680503845, 0.2771350145339966, 0.31657272577285767, 0.2811182737350464, 0.24327687919139862, 0.3427272140979767, 0.3325706422328949, 0.22931167483329773, 0.3042820692062378], \"yaxis\": \"y2\"}],\n",
       "                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Training and validation accuracy\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Training and validation loss\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45], \"title\": {\"text\": \"Epoch\"}}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0], \"title\": {\"text\": \"Epoch\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"range\": [0, 1], \"title\": {\"text\": \"Accuracy\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0], \"range\": [0, 1], \"title\": {\"text\": \"Loss\"}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('8037ccc9-4d56-4671-b295-005c80d74749');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_accuracy_and_loss(train_model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score = model1.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3 w/ refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "annealer3 = LearningRateScheduler(lambda x: 1e-3 * 0.995 ** (x+NO_EPOCHS_3))\n",
    "earlystopper3 = EarlyStopping(monitor='loss', patience=PATIENCE, verbose=VERBOSE)\n",
    "checkpointer3 = ModelCheckpoint('best_model_3.h5',\n",
    "                                monitor='val_acc',\n",
    "                                verbose=VERBOSE,\n",
    "                                save_best_only=True,\n",
    "                                save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model3=Sequential()\n",
    "model3.add(Conv2D(CONV_2D_DIM_1, kernel_size=KERNEL_SIZE, input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT,IMAGE_CHANNELS), activation='relu', padding='same'))\n",
    "model3.add(MaxPool2D(MAX_POOL_DIM))\n",
    "# Add dropouts to the model\n",
    "model3.add(Dropout(0.4))\n",
    "model3.add(Conv2D(CONV_2D_DIM_2, kernel_size=KERNEL_SIZE, activation='relu', padding='same'))\n",
    "# Add dropouts to the model\n",
    "model3.add(Dropout(0.4))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(y_train.columns.size, activation='softmax'))\n",
    "model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 100, 100, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 50, 50, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50, 50, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 50, 50, 16)        2320      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50, 50, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 40000)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 280007    \n",
      "=================================================================\n",
      "Total params: 282,775\n",
      "Trainable params: 282,775\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "104/103 [==============================] - ETA: 0s - loss: 0.4795 - accuracy: 0.8150"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\kekay\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1224 test_function  *\n        return step_function(self, iterator)\n    C:\\Users\\kekay\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1215 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\kekay\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\kekay\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\kekay\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\kekay\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1208 run_step  **\n        outputs = model.test_step(data)\n    C:\\Users\\kekay\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1174 test_step\n        y_pred = self(x, training=False)\n    C:\\Users\\kekay\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:976 __call__\n        self.name)\n    C:\\Users\\kekay\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:158 assert_input_compatibility\n        ' input tensors. Inputs received: ' + str(inputs))\n\n    ValueError: Layer sequential_2 expects 1 inputs, but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 100, 100, 3) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 7) dtype=uint8>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-f0d98118d129>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                         callbacks=(earlystopper3, checkpointer3, annealer3))\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1827\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1828\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1829\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1831\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m               return_dict=True)\n\u001b[0m\u001b[0;32m   1134\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'val_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1377\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TraceContext'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1379\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1380\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2826\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2828\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2829\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3208\u001b[0m           \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3209\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[1;32m-> 3210\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3141\u001b[0m     graph_function = self._create_graph_function(\n\u001b[1;32m-> 3142\u001b[1;33m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[0;32m   3143\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3075\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\kekay\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1224 test_function  *\n        return step_function(self, iterator)\n    C:\\Users\\kekay\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1215 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\kekay\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\kekay\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\kekay\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\kekay\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1208 run_step  **\n        outputs = model.test_step(data)\n    C:\\Users\\kekay\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1174 test_step\n        y_pred = self(x, training=False)\n    C:\\Users\\kekay\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:976 __call__\n        self.name)\n    C:\\Users\\kekay\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:158 assert_input_compatibility\n        ' input tensors. Inputs received: ' + str(inputs))\n\n    ValueError: Layer sequential_2 expects 1 inputs, but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 100, 100, 3) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 7) dtype=uint8>]\n"
     ]
    }
   ],
   "source": [
    "train_model3  = model3.fit_generator(image_generator.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                        epochs=NO_EPOCHS_3,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        steps_per_epoch=len(X_train)/BATCH_SIZE,\n",
    "                        callbacks=(earlystopper3, checkpointer3, annealer3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_accuracy_and_loss(train_model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_accuracy_report(model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
